{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97abf5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "Path\n",
      "A -> B -> D\n",
      "Cost\n",
      "0 -> 1 -> 6\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.a_star_search import AStar\n",
    "\n",
    "print(\"Graph-1\")\n",
    "\n",
    "heuristic = {'A':1,'B':1,'C':11,'D':1}\n",
    "adjance_list = {'A':[('B',1),('C',3),('D',7),],'B':[('D',5 )],'C':[('D',12)]}\n",
    "\n",
    "graph=AStar(adjance_list,heuristic)\n",
    "graph.apply_a_star(start='A',stop='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3657412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "11 ['D']\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "6 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "7 ['D']\n",
      "\n",
      "PROCESSING NODE : E\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "PROCESSING NODE : F\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "FOR THE SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE: A\n",
      "------------------------------------------------------------\n",
      "{'E': [], 'F': [], 'D': ['E', 'F'], 'A': ['D']}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.ao_star import AOStar\n",
    "print(\"Graph-1\")\n",
    "heuristic={'A':1,'B':6,'C':12,'D':10,'E':4,'G':5,'H':7}\n",
    "adjancency_list = {'A':[[('B',1),('C',1)],[('D',1)]],\n",
    "                   'B':[[('G',1)],[('H',1)]],\n",
    "                   'C':[[('J',1)]],\n",
    "                   'D':[[('E',1),('F',1)]],\n",
    "                   'G':[[('I',1)]]\n",
    "                  }\n",
    "graph=AOStar(adjancency_list, heuristic, 'A')\n",
    "graph.applyAOStar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cd94b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Steps for candidate elimination algorithm 1\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 2\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 3\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 4\n",
      "['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Final Specific Hypothesis:\n",
      " ['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "\n",
      " Final General Hypothesis:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('pro3.csv') as f:\n",
    "    csv_file=csv.reader(f)\n",
    "    data=list(csv_file)\n",
    "\n",
    "    s=data[1][:-1]\n",
    "    g=[['?' for i in range(len(s))] for j in range(len(s))] \n",
    "\n",
    "    for i in data:\n",
    "        if i[-1]==\"Yes\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    s[j]='?'\n",
    "                    g[j][j]='?'\n",
    "        elif i[-1]==\"No\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    g[j][j]=s[j]\n",
    "                else:\n",
    "                    g[j][j]=\"?\"\n",
    "        print(\"\\n Steps for candidate elimination algorithm\",data.index(i)+1)\n",
    "        print(s)\n",
    "        print(g)\n",
    "\n",
    "    gh=[]\n",
    "\n",
    "    for i in g:\n",
    "        for j in i:\n",
    "            if j!=\"?\":\n",
    "                gh.append(i)\n",
    "                break\n",
    "\n",
    "    print(\"\\n Final Specific Hypothesis:\\n\",s)\n",
    "    print(\"\\n Final General Hypothesis:\\n\", gh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e18e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.9166666666666666, 'x[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(0.4230769230769231, 0.75, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(0.5769230769230769, 0.75, 'x[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(0.3076923076923077, 0.5833333333333334, 'x[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(0.15384615384615385, 0.4166666666666667, 'x[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(0.07692307692307693, 0.25, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
       " Text(0.23076923076923078, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.46153846153846156, 0.4166666666666667, 'x[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(0.38461538461538464, 0.25, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(0.5384615384615384, 0.25, 'x[0] <= 6.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(0.46153846153846156, 0.08333333333333333, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(0.6153846153846154, 0.08333333333333333, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.8461538461538461, 0.5833333333333334, 'x[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(0.7692307692307693, 0.4166666666666667, 'x[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(0.6923076923076923, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(0.8461538461538461, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(0.9230769230769231, 0.4166666666666667, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X= [[0,0],[1,1]]\n",
    "Y= [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)\n",
    "clf.predict([[2.,2.]])\n",
    "clf.predict_proba([[2.,2.]])\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris= load_iris()\n",
    "X,y = iris.data,iris.target\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "clf=clf.fit(X,y)\n",
    "tree.plot_tree(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fa0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 9.]\n",
      "Epoch: 0\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51846402]\n",
      " [0.49935614]\n",
      " [0.49170618]]\n",
      "Loss: \n",
      " 0.14997770019033277\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5288656 ]\n",
      " [0.50860541]\n",
      " [0.50177272]]\n",
      "Loss: \n",
      " 0.14239489982146267\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.53894632]\n",
      " [0.51759268]\n",
      " [0.51155073]]\n",
      "Loss: \n",
      " 0.13522284136688084\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.54870423]\n",
      " [0.52631546]\n",
      " [0.52103681]]\n",
      "Loss: \n",
      " 0.12844658648598553\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.55813973]\n",
      " [0.53477312]\n",
      " [0.5302298 ]]\n",
      "Loss: \n",
      " 0.12204999089376763\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56725527]\n",
      " [0.54296673]\n",
      " [0.53913053]]\n",
      "Loss: \n",
      " 0.11601610697693254\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.57605503]\n",
      " [0.55089878]\n",
      " [0.54774149]]\n",
      "Loss: \n",
      " 0.110327531020342\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58454461]\n",
      " [0.55857295]\n",
      " [0.55606662]]\n",
      "Loss: \n",
      " 0.10496669615918632\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.59273076]\n",
      " [0.56599393]\n",
      " [0.56411104]]\n",
      "Loss: \n",
      " 0.09991611409455327\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60062116]\n",
      " [0.57316721]\n",
      " [0.57188081]]\n",
      "Loss: \n",
      " 0.09515856986071791\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60822421]\n",
      " [0.58009893]\n",
      " [0.57938276]]\n",
      "Loss: \n",
      " 0.09067727463181724\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6155488 ]\n",
      " [0.58679571]\n",
      " [0.58662428]]\n",
      "Loss: \n",
      " 0.08645598182640268\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62260418]\n",
      " [0.59326453]\n",
      " [0.59361321]]\n",
      "Loss: \n",
      " 0.08247907172439614\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62939982]\n",
      " [0.59951262]\n",
      " [0.60035766]]\n",
      "Loss: \n",
      " 0.07873160955040698\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.63594529]\n",
      " [0.60554734]\n",
      " [0.60686591]]\n",
      "Loss: \n",
      " 0.07519938158041795\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64225016]\n",
      " [0.61137614]\n",
      " [0.61314636]]\n",
      "Loss: \n",
      " 0.07186891335788019\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64832391]\n",
      " [0.61700644]\n",
      " [0.61920736]]\n",
      "Loss: \n",
      " 0.06872747360646604\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6541759 ]\n",
      " [0.62244564]\n",
      " [0.62505723]]\n",
      "Loss: \n",
      " 0.0657630669325814\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65981527]\n",
      " [0.62770099]\n",
      " [0.63070416]]\n",
      "Loss: \n",
      " 0.06296441794262904\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66525097]\n",
      " [0.63277963]\n",
      " [0.63615618]]\n",
      "Loss: \n",
      " 0.06032094897078514\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67049165]\n",
      " [0.63768854]\n",
      " [0.64142113]]\n",
      "Loss: \n",
      " 0.057822753229212105\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67554569]\n",
      " [0.64243447]\n",
      " [0.64650662]]\n",
      "Loss: \n",
      " 0.05546056485622889\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68042117]\n",
      " [0.64702401]\n",
      " [0.65142005]]\n",
      "Loss: \n",
      " 0.05322572704800801\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68512588]\n",
      " [0.6514635 ]\n",
      " [0.65616853]]\n",
      "Loss: \n",
      " 0.051110159213010396\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68966729]\n",
      " [0.65575907]\n",
      " [0.66075896]]\n",
      "Loss: \n",
      " 0.04910632388166399\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69405254]\n",
      " [0.65991662]\n",
      " [0.66519793]]\n",
      "Loss: \n",
      " 0.04720719393233014\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6982885 ]\n",
      " [0.66394181]\n",
      " [0.66949182]]\n",
      "Loss: \n",
      " 0.04540622055387907\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7023817 ]\n",
      " [0.66784009]\n",
      " [0.6736467 ]]\n",
      "Loss: \n",
      " 0.043697302250887325\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7063384 ]\n",
      " [0.67161667]\n",
      " [0.6776684 ]]\n",
      "Loss: \n",
      " 0.042074755105559976\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71016455]\n",
      " [0.67527655]\n",
      " [0.68156252]]\n",
      "Loss: \n",
      " 0.04053328443736685\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71386584]\n",
      " [0.6788245 ]\n",
      " [0.68533438]]\n",
      "Loss: \n",
      " 0.039067957943876075\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71744767]\n",
      " [0.68226509]\n",
      " [0.68898907]]\n",
      "Loss: \n",
      " 0.0376741803616187\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7209152 ]\n",
      " [0.68560268]\n",
      " [0.69253146]]\n",
      "Loss: \n",
      " 0.036347669651659434\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72427334]\n",
      " [0.68884143]\n",
      " [0.69596618]]\n",
      "Loss: \n",
      " 0.03508443468889152\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72752674]\n",
      " [0.69198534]\n",
      " [0.69929767]]\n",
      "Loss: \n",
      " 0.03388075441524496\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73067984]\n",
      " [0.69503819]\n",
      " [0.70253013]]\n",
      "Loss: \n",
      " 0.03273315840361301\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73373686]\n",
      " [0.6980036 ]\n",
      " [0.7056676 ]]\n",
      "Loss: \n",
      " 0.031638408770214545\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73670182]\n",
      " [0.70088503]\n",
      " [0.70871389]]\n",
      "Loss: \n",
      " 0.030593483367391146\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73957853]\n",
      " [0.70368577]\n",
      " [0.71167268]]\n",
      "Loss: \n",
      " 0.02959556018572032\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74237062]\n",
      " [0.70640897]\n",
      " [0.71454742]]\n",
      "Loss: \n",
      " 0.028642002893202106\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74508154]\n",
      " [0.70905763]\n",
      " [0.71734144]]\n",
      "Loss: \n",
      " 0.027730347439647363\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74771459]\n",
      " [0.7116346 ]\n",
      " [0.72005791]]\n",
      "Loss: \n",
      " 0.026858289655873547\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75027287]\n",
      " [0.71414262]\n",
      " [0.72269983]]\n",
      "Loss: \n",
      " 0.026023673779580564\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75275937]\n",
      " [0.71658428]\n",
      " [0.72527007]]\n",
      "Loss: \n",
      " 0.02522448184259805\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75517691]\n",
      " [0.71896208]\n",
      " [0.72777138]]\n",
      "Loss: \n",
      " 0.0244588238573655\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75752818]\n",
      " [0.72127838]\n",
      " [0.73020636]]\n",
      "Loss: \n",
      " 0.023724928743889998\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75981576]\n",
      " [0.72353544]\n",
      " [0.73257751]]\n",
      "Loss: \n",
      " 0.023021135941902148\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76204209]\n",
      " [0.72573542]\n",
      " [0.73488719]]\n",
      "Loss: \n",
      " 0.02234588765641929\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76420948]\n",
      " [0.7278804 ]\n",
      " [0.73713768]]\n",
      "Loss: \n",
      " 0.0216977216883613\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76632016]\n",
      " [0.72997233]\n",
      " [0.73933113]]\n",
      "Loss: \n",
      " 0.02107526480520291\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76837625]\n",
      " [0.73201311]\n",
      " [0.74146962]]\n",
      "Loss: \n",
      " 0.02047722660985611\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77037976]\n",
      " [0.73400452]\n",
      " [0.74355512]]\n",
      "Loss: \n",
      " 0.019902393869035594\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77233261]\n",
      " [0.7359483 ]\n",
      " [0.7455895 ]]\n",
      "Loss: \n",
      " 0.019349625265257426\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77423663]\n",
      " [0.73784609]\n",
      " [0.74757457]]\n",
      "Loss: \n",
      " 0.018817846539346386\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77609359]\n",
      " [0.73969946]\n",
      " [0.74951206]]\n",
      "Loss: \n",
      " 0.01830604599288442\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77790515]\n",
      " [0.74150991]\n",
      " [0.7514036 ]]\n",
      "Loss: \n",
      " 0.017813270322416936\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77967291]\n",
      " [0.7432789 ]\n",
      " [0.75325076]]\n",
      "Loss: \n",
      " 0.017338620759453766\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78139839]\n",
      " [0.74500779]\n",
      " [0.75505506]]\n",
      "Loss: \n",
      " 0.01688124949236185\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78308307]\n",
      " [0.74669792]\n",
      " [0.75681794]]\n",
      "Loss: \n",
      " 0.016440356348154137\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78472832]\n",
      " [0.74835054]\n",
      " [0.75854077]]\n",
      "Loss: \n",
      " 0.016015185713942132\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7863355 ]\n",
      " [0.74996687]\n",
      " [0.76022488]]\n",
      "Loss: \n",
      " 0.015605023679447097\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78790587]\n",
      " [0.75154808]\n",
      " [0.76187152]]\n",
      "Loss: \n",
      " 0.015209195383463365\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78944065]\n",
      " [0.75309528]\n",
      " [0.76348192]]\n",
      "Loss: \n",
      " 0.014827062548548334\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79094103]\n",
      " [0.75460954]\n",
      " [0.76505723]]\n",
      "Loss: \n",
      " 0.014458021189482617\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79240811]\n",
      " [0.75609189]\n",
      " [0.76659857]]\n",
      "Loss: \n",
      " 0.014101499482210478\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79384298]\n",
      " [0.75754331]\n",
      " [0.76810702]]\n",
      "Loss: \n",
      " 0.013756955781042676\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79524666]\n",
      " [0.75896475]\n",
      " [0.76958358]]\n",
      "Loss: \n",
      " 0.013423876772886792\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79662015]\n",
      " [0.76035712]\n",
      " [0.77102926]]\n",
      "Loss: \n",
      " 0.013101775758173723\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79796439]\n",
      " [0.7617213 ]\n",
      " [0.772445  ]]\n",
      "Loss: \n",
      " 0.01279019104897666\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79928029]\n",
      " [0.76305811]\n",
      " [0.77383169]]\n",
      "Loss: \n",
      " 0.012488684475578785\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80056872]\n",
      " [0.76436838]\n",
      " [0.77519023]]\n",
      "Loss: \n",
      " 0.012196839993442522\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80183053]\n",
      " [0.76565288]\n",
      " [0.77652144]]\n",
      "Loss: \n",
      " 0.011914262383173238\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80306651]\n",
      " [0.76691235]\n",
      " [0.77782614]]\n",
      "Loss: \n",
      " 0.011640576036654393\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80427744]\n",
      " [0.76814751]\n",
      " [0.77910509]]\n",
      "Loss: \n",
      " 0.011375423823071091\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80546406]\n",
      " [0.76935906]\n",
      " [0.78035905]]\n",
      "Loss: \n",
      " 0.011118466029030218\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8066271 ]\n",
      " [0.77054766]\n",
      " [0.78158873]]\n",
      "Loss: \n",
      " 0.010869379367438871\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80776723]\n",
      " [0.77171395]\n",
      " [0.78279483]]\n",
      "Loss: \n",
      " 0.010627856050217705\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80888513]\n",
      " [0.77285856]\n",
      " [0.78397801]]\n",
      "Loss: \n",
      " 0.01039360292030612\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80998141]\n",
      " [0.77398207]\n",
      " [0.78513891]]\n",
      "Loss: \n",
      " 0.010166340638767596\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81105671]\n",
      " [0.77508507]\n",
      " [0.78627815]]\n",
      "Loss: \n",
      " 0.009945802923122884\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81211161]\n",
      " [0.7761681 ]\n",
      " [0.78739632]]\n",
      "Loss: \n",
      " 0.009731735833335265\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81314667]\n",
      " [0.77723171]\n",
      " [0.788494  ]]\n",
      "Loss: \n",
      " 0.009523897102142334\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81416246]\n",
      " [0.7782764 ]\n",
      " [0.78957175]]\n",
      "Loss: \n",
      " 0.00932205550667853\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81515948]\n",
      " [0.77930267]\n",
      " [0.79063009]]\n",
      "Loss: \n",
      " 0.009125990278561454\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81613827]\n",
      " [0.78031102]\n",
      " [0.79166955]]\n",
      "Loss: \n",
      " 0.008935490549825988\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81709929]\n",
      " [0.78130189]\n",
      " [0.79269061]]\n",
      "Loss: \n",
      " 0.008750354832283916\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81804304]\n",
      " [0.78227574]\n",
      " [0.79369377]]\n",
      "Loss: \n",
      " 0.008570390528065939\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81896997]\n",
      " [0.783233  ]\n",
      " [0.79467948]]\n",
      "Loss: \n",
      " 0.008395413469266462\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81988052]\n",
      " [0.78417409]\n",
      " [0.7956482 ]]\n",
      "Loss: \n",
      " 0.008225247484763783\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82077511]\n",
      " [0.78509942]\n",
      " [0.79660035]]\n",
      "Loss: \n",
      " 0.008059723992427784\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82165416]\n",
      " [0.78600937]\n",
      " [0.79753635]]\n",
      "Loss: \n",
      " 0.00789868161505555\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82251806]\n",
      " [0.78690433]\n",
      " [0.79845661]]\n",
      "Loss: \n",
      " 0.0077419658184946045\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82336721]\n",
      " [0.78778466]\n",
      " [0.79936152]]\n",
      "Loss: \n",
      " 0.007589428570522906\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82420196]\n",
      " [0.78865072]\n",
      " [0.80025146]]\n",
      "Loss: \n",
      " 0.007440928019155503\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82502269]\n",
      " [0.78950285]\n",
      " [0.8011268 ]]\n",
      "Loss: \n",
      " 0.007296328189142091\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82582974]\n",
      " [0.79034137]\n",
      " [0.80198788]]\n",
      "Loss: \n",
      " 0.007155498695505003\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82662344]\n",
      " [0.79116662]\n",
      " [0.80283505]]\n",
      "Loss: \n",
      " 0.007018314473047969\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82740412]\n",
      " [0.79197891]\n",
      " [0.80366865]]\n",
      "Loss: \n",
      " 0.006884655520839168\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8281721 ]\n",
      " [0.79277853]\n",
      " [0.804489  ]]\n",
      "Loss: \n",
      " 0.0067544066607406646\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82892768]\n",
      " [0.79356579]\n",
      " [0.8052964 ]]\n",
      "Loss: \n",
      " 0.006627457309119675\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82967116]\n",
      " [0.79434095]\n",
      " [0.80609116]]\n",
      "Loss: \n",
      " 0.006503701260935427\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83040281]\n",
      " [0.79510431]\n",
      " [0.80687357]]\n",
      "Loss: \n",
      " 0.006383036485449831\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83112293]\n",
      " [0.79585612]\n",
      " [0.80764392]]\n",
      "Loss: \n",
      " 0.0062653649328604935\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83183177]\n",
      " [0.79659664]\n",
      " [0.80840248]]\n",
      "Loss: \n",
      " 0.006150592351201072\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83252961]\n",
      " [0.79732613]\n",
      " [0.80914951]]\n",
      "Loss: \n",
      " 0.006038628112897559\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83321668]\n",
      " [0.79804483]\n",
      " [0.80988529]]\n",
      "Loss: \n",
      " 0.005929385050408888\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83389323]\n",
      " [0.79875298]\n",
      " [0.81061004]]\n",
      "Loss: \n",
      " 0.005822779300417868\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83455951]\n",
      " [0.7994508 ]\n",
      " [0.81132403]]\n",
      "Loss: \n",
      " 0.005718730156073081\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83521574]\n",
      " [0.80013852]\n",
      " [0.81202749]]\n",
      "Loss: \n",
      " 0.005617159926814125\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83586215]\n",
      " [0.80081635]\n",
      " [0.81272064]]\n",
      "Loss: \n",
      " 0.00551799380534338\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83649894]\n",
      " [0.80148451]\n",
      " [0.81340372]]\n",
      "Loss: \n",
      " 0.0054211597413345485\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83712635]\n",
      " [0.8021432 ]\n",
      " [0.81407692]]\n",
      "Loss: \n",
      " 0.005326588321494449\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83774455]\n",
      " [0.80279262]\n",
      " [0.81474048]]\n",
      "Loss: \n",
      " 0.0052342126556189075\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83835377]\n",
      " [0.80343296]\n",
      " [0.81539459]]\n",
      "Loss: \n",
      " 0.005143968268305534\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83895418]\n",
      " [0.80406441]\n",
      " [0.81603944]]\n",
      "Loss: \n",
      " 0.005055792996007658\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83954598]\n",
      " [0.80468715]\n",
      " [0.81667524]]\n",
      "Loss: \n",
      " 0.004969626889132786\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84012935]\n",
      " [0.80530136]\n",
      " [0.81730217]]\n",
      "Loss: \n",
      " 0.0048854121189076715\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84070446]\n",
      " [0.80590722]\n",
      " [0.81792041]]\n",
      "Loss: \n",
      " 0.004803092888748271\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84127149]\n",
      " [0.80650488]\n",
      " [0.81853015]]\n",
      "Loss: \n",
      " 0.004722615349889714\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8418306 ]\n",
      " [0.80709452]\n",
      " [0.81913154]]\n",
      "Loss: \n",
      " 0.00464392752104525\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84238196]\n",
      " [0.80767629]\n",
      " [0.81972477]]\n",
      "Loss: \n",
      " 0.0045669792118777554\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84292573]\n",
      " [0.80825035]\n",
      " [0.82031   ]]\n",
      "Loss: \n",
      " 0.004491721950079759\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84346205]\n",
      " [0.80881685]\n",
      " [0.82088737]]\n",
      "Loss: \n",
      " 0.004418108911870317\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84399109]\n",
      " [0.80937594]\n",
      " [0.82145706]]\n",
      "Loss: \n",
      " 0.004346094855728203\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84451297]\n",
      " [0.80992776]\n",
      " [0.82201921]]\n",
      "Loss: \n",
      " 0.004275636059191617\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84502786]\n",
      " [0.81047245]\n",
      " [0.82257396]]\n",
      "Loss: \n",
      " 0.004206690258564387\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84553588]\n",
      " [0.81101014]\n",
      " [0.82312147]]\n",
      "Loss: \n",
      " 0.004139216591377735\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84603717]\n",
      " [0.81154097]\n",
      " [0.82366186]]\n",
      "Loss: \n",
      " 0.004073175541465853\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84653186]\n",
      " [0.81206507]\n",
      " [0.82419529]]\n",
      "Loss: \n",
      " 0.004008528886521165\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84702007]\n",
      " [0.81258255]\n",
      " [0.82472186]]\n",
      "Loss: \n",
      " 0.0039452396480028915\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84750194]\n",
      " [0.81309356]\n",
      " [0.82524173]]\n",
      "Loss: \n",
      " 0.0038832720432799162\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84797758]\n",
      " [0.8135982 ]\n",
      " [0.82575501]]\n",
      "Loss: \n",
      " 0.0038225914398953356\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84844712]\n",
      " [0.81409659]\n",
      " [0.82626183]]\n",
      "Loss: \n",
      " 0.0037631643118465953\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84891066]\n",
      " [0.81458885]\n",
      " [0.8267623 ]]\n",
      "Loss: \n",
      " 0.003704958197780782\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84936832]\n",
      " [0.81507508]\n",
      " [0.82725654]]\n",
      "Loss: \n",
      " 0.0036479416610106247\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8498202 ]\n",
      " [0.8155554 ]\n",
      " [0.82774467]]\n",
      "Loss: \n",
      " 0.003592084251261245\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85026642]\n",
      " [0.81602991]\n",
      " [0.82822679]]\n",
      "Loss: \n",
      " 0.003537356468063427\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85070709]\n",
      " [0.81649871]\n",
      " [0.82870302]]\n",
      "Loss: \n",
      " 0.0034837297257131056\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85114229]\n",
      " [0.81696191]\n",
      " [0.82917347]]\n",
      "Loss: \n",
      " 0.0034311763197214314\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85157213]\n",
      " [0.8174196 ]\n",
      " [0.82963822]]\n",
      "Loss: \n",
      " 0.00337966939468377\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8519967 ]\n",
      " [0.81787188]\n",
      " [0.83009739]]\n",
      "Loss: \n",
      " 0.0033291829134999146\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85241611]\n",
      " [0.81831885]\n",
      " [0.83055108]]\n",
      "Loss: \n",
      " 0.0032796916278809755\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85283044]\n",
      " [0.81876059]\n",
      " [0.83099937]]\n",
      "Loss: \n",
      " 0.0032311710500826374\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85323978]\n",
      " [0.81919719]\n",
      " [0.83144237]]\n",
      "Loss: \n",
      " 0.0031835974258066662\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85364423]\n",
      " [0.81962874]\n",
      " [0.83188016]]\n",
      "Loss: \n",
      " 0.003136947708216331\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85404386]\n",
      " [0.82005534]\n",
      " [0.83231283]]\n",
      "Loss: \n",
      " 0.003091199533013965\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85443875]\n",
      " [0.82047705]\n",
      " [0.83274048]]\n",
      "Loss: \n",
      " 0.0030463311945314792\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.854829  ]\n",
      " [0.82089396]\n",
      " [0.83316318]]\n",
      "Loss: \n",
      " 0.003002321622787289\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85521468]\n",
      " [0.82130616]\n",
      " [0.83358102]]\n",
      "Loss: \n",
      " 0.0029591503614654637\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85559588]\n",
      " [0.82171372]\n",
      " [0.83399409]]\n",
      "Loss: \n",
      " 0.0029167975467753182\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85597265]\n",
      " [0.82211671]\n",
      " [0.83440246]]\n",
      "Loss: \n",
      " 0.0028752438871513333\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85634509]\n",
      " [0.82251522]\n",
      " [0.8348062 ]]\n",
      "Loss: \n",
      " 0.002834470643755867\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85671326]\n",
      " [0.82290931]\n",
      " [0.83520541]]\n",
      "Loss: \n",
      " 0.002794459611748639\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85707723]\n",
      " [0.82329906]\n",
      " [0.83560014]]\n",
      "Loss: \n",
      " 0.0027551931022888406\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85743708]\n",
      " [0.82368453]\n",
      " [0.83599048]]\n",
      "Loss: \n",
      " 0.0027166539252374763\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85779286]\n",
      " [0.82406579]\n",
      " [0.83637649]]\n",
      "Loss: \n",
      " 0.0026788253725291296\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85814466]\n",
      " [0.82444292]\n",
      " [0.83675824]]\n",
      "Loss: \n",
      " 0.002641691202183745\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85849253]\n",
      " [0.82481597]\n",
      " [0.83713581]]\n",
      "Loss: \n",
      " 0.0026052356229306233\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85883654]\n",
      " [0.82518501]\n",
      " [0.83750926]]\n",
      "Loss: \n",
      " 0.0025694432794180623\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85917675]\n",
      " [0.8255501 ]\n",
      " [0.83787866]]\n",
      "Loss: \n",
      " 0.0025342992379833898\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85951322]\n",
      " [0.82591131]\n",
      " [0.83824406]]\n",
      "Loss: \n",
      " 0.002499788972959303\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.859846  ]\n",
      " [0.8262687 ]\n",
      " [0.83860554]]\n",
      "Loss: \n",
      " 0.002465898353493779\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86017517]\n",
      " [0.82662231]\n",
      " [0.83896314]]\n",
      "Loss: \n",
      " 0.0024326136308614986\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86050077]\n",
      " [0.82697222]\n",
      " [0.83931694]]\n",
      "Loss: \n",
      " 0.002399921426246287\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86082287]\n",
      " [0.82731847]\n",
      " [0.839667  ]]\n",
      "Loss: \n",
      " 0.0023678087189745894\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86114151]\n",
      " [0.82766113]\n",
      " [0.84001336]]\n",
      "Loss: \n",
      " 0.002336262835181174\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86145675]\n",
      " [0.82800024]\n",
      " [0.84035609]]\n",
      "Loss: \n",
      " 0.0023052714368891314\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86176865]\n",
      " [0.82833587]\n",
      " [0.84069524]]\n",
      "Loss: \n",
      " 0.0022748225114869454\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86207724]\n",
      " [0.82866805]\n",
      " [0.84103086]]\n",
      "Loss: \n",
      " 0.0022449043615862863\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8623826 ]\n",
      " [0.82899685]\n",
      " [0.84136301]]\n",
      "Loss: \n",
      " 0.0022155055952450004\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86268475]\n",
      " [0.82932231]\n",
      " [0.84169175]]\n",
      "Loss: \n",
      " 0.002186615116540264\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86298376]\n",
      " [0.82964449]\n",
      " [0.84201711]]\n",
      "Loss: \n",
      " 0.0021582221164778603\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86327967]\n",
      " [0.82996342]\n",
      " [0.84233916]]\n",
      "Loss: \n",
      " 0.0021303160642238074\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86357252]\n",
      " [0.83027916]\n",
      " [0.84265793]]\n",
      "Loss: \n",
      " 0.0021028866986455533\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86386237]\n",
      " [0.83059175]\n",
      " [0.84297348]]\n",
      "Loss: \n",
      " 0.002075924020150276\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86414925]\n",
      " [0.83090124]\n",
      " [0.84328586]]\n",
      "Loss: \n",
      " 0.002049418282808449\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86443321]\n",
      " [0.83120767]\n",
      " [0.84359511]]\n",
      "Loss: \n",
      " 0.0020233599867514255\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8647143 ]\n",
      " [0.83151109]\n",
      " [0.84390127]]\n",
      "Loss: \n",
      " 0.0019977398708321973\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86499255]\n",
      " [0.83181154]\n",
      " [0.8442044 ]]\n",
      "Loss: \n",
      " 0.001972548905538995\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.865268  ]\n",
      " [0.83210906]\n",
      " [0.84450452]]\n",
      "Loss: \n",
      " 0.0019477782861519136\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8655407 ]\n",
      " [0.83240369]\n",
      " [0.8448017 ]]\n",
      "Loss: \n",
      " 0.0019234194261330412\n",
      "\n",
      "\n",
      "Epoch: 181\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86581069]\n",
      " [0.83269547]\n",
      " [0.84509596]]\n",
      "Loss: \n",
      " 0.0018994639507411391\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.866078  ]\n",
      " [0.83298445]\n",
      " [0.84538735]]\n",
      "Loss: \n",
      " 0.0018759036908621337\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86634267]\n",
      " [0.83327065]\n",
      " [0.84567591]]\n",
      "Loss: \n",
      " 0.001852730677047245\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86660474]\n",
      " [0.83355413]\n",
      " [0.84596168]]\n",
      "Loss: \n",
      " 0.0018299371337507685\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86686425]\n",
      " [0.8338349 ]\n",
      " [0.8462447 ]]\n",
      "Loss: \n",
      " 0.0018075154737599356\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86712123]\n",
      " [0.83411303]\n",
      " [0.846525  ]]\n",
      "Loss: \n",
      " 0.0017854582928096606\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86737572]\n",
      " [0.83438853]\n",
      " [0.84680263]]\n",
      "Loss: \n",
      " 0.0017637583643750822\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86762775]\n",
      " [0.83466144]\n",
      " [0.84707761]]\n",
      "Loss: \n",
      " 0.0017424086346353822\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86787736]\n",
      " [0.8349318 ]\n",
      " [0.84735   ]]\n",
      "Loss: \n",
      " 0.0017214022176024353\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86812458]\n",
      " [0.83519965]\n",
      " [0.84761981]]\n",
      "Loss: \n",
      " 0.001700732390408144\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86836944]\n",
      " [0.83546501]\n",
      " [0.84788709]]\n",
      "Loss: \n",
      " 0.0016803925887446426\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86861198]\n",
      " [0.83572792]\n",
      " [0.84815186]]\n",
      "Loss: \n",
      " 0.0016603764024517508\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86885222]\n",
      " [0.83598842]\n",
      " [0.84841417]]\n",
      "Loss: \n",
      " 0.0016406775712462292\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8690902 ]\n",
      " [0.83624652]\n",
      " [0.84867405]]\n",
      "Loss: \n",
      " 0.0016212899805877385\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86932594]\n",
      " [0.83650227]\n",
      " [0.84893152]]\n",
      "Loss: \n",
      " 0.0016022076576764981\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86955949]\n",
      " [0.8367557 ]\n",
      " [0.84918663]]\n",
      "Loss: \n",
      " 0.0015834247675778573\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86979086]\n",
      " [0.83700683]\n",
      " [0.84943939]]\n",
      "Loss: \n",
      " 0.001564935609469361\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87002008]\n",
      " [0.8372557 ]\n",
      " [0.84968985]]\n",
      "Loss: \n",
      " 0.001546734613005668\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87024719]\n",
      " [0.83750233]\n",
      " [0.84993802]]\n",
      "Loss: \n",
      " 0.0015288163347973638\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87047222]\n",
      " [0.83774675]\n",
      " [0.85018395]]\n",
      "Loss: \n",
      " 0.0015111754549995196\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87069518]\n",
      " [0.83798899]\n",
      " [0.85042766]]\n",
      "Loss: \n",
      " 0.0014938067740060904\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8709161 ]\n",
      " [0.83822908]\n",
      " [0.85066917]]\n",
      "Loss: \n",
      " 0.0014767052092464633\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87113502]\n",
      " [0.83846705]\n",
      " [0.85090853]]\n",
      "Loss: \n",
      " 0.0014598657920806143\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87135196]\n",
      " [0.83870291]\n",
      " [0.85114574]]\n",
      "Loss: \n",
      " 0.001443283664789325\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87156694]\n",
      " [0.83893671]\n",
      " [0.85138085]]\n",
      "Loss: \n",
      " 0.0014269540776562894\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87177999]\n",
      " [0.83916846]\n",
      " [0.85161387]]\n",
      "Loss: \n",
      " 0.0014108723861388254\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87199113]\n",
      " [0.83939819]\n",
      " [0.85184484]]\n",
      "Loss: \n",
      " 0.0013950340481241547\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87220039]\n",
      " [0.83962592]\n",
      " [0.85207378]]\n",
      "Loss: \n",
      " 0.0013794346212684173\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87240779]\n",
      " [0.83985168]\n",
      " [0.85230071]]\n",
      "Loss: \n",
      " 0.0013640697604154048\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87261336]\n",
      " [0.84007549]\n",
      " [0.85252566]]\n",
      "Loss: \n",
      " 0.0013489352150924828\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87281711]\n",
      " [0.84029738]\n",
      " [0.85274866]]\n",
      "Loss: \n",
      " 0.0013340268270810073\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87301907]\n",
      " [0.84051737]\n",
      " [0.85296972]]\n",
      "Loss: \n",
      " 0.001319340528058663\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87321927]\n",
      " [0.84073549]\n",
      " [0.85318888]]\n",
      "Loss: \n",
      " 0.0013048723373114699\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87341772]\n",
      " [0.84095174]\n",
      " [0.85340615]]\n",
      "Loss: \n",
      " 0.0012906183595129059\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87361445]\n",
      " [0.84116617]\n",
      " [0.85362155]]\n",
      "Loss: \n",
      " 0.0012765747825681268\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87380947]\n",
      " [0.84137878]\n",
      " [0.85383512]]\n",
      "Loss: \n",
      " 0.001262737875520962\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87400281]\n",
      " [0.84158961]\n",
      " [0.85404687]]\n",
      "Loss: \n",
      " 0.0012491039865217197\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87419448]\n",
      " [0.84179866]\n",
      " [0.85425682]]\n",
      "Loss: \n",
      " 0.0012356695408536902\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87438452]\n",
      " [0.84200597]\n",
      " [0.854465  ]]\n",
      "Loss: \n",
      " 0.001222431039016509\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87457293]\n",
      " [0.84221156]\n",
      " [0.85467143]]\n",
      "Loss: \n",
      " 0.0012093850548645542\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87475974]\n",
      " [0.84241543]\n",
      " [0.85487612]]\n",
      "Loss: \n",
      " 0.0011965282337983976\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87494497]\n",
      " [0.84261762]\n",
      " [0.8550791 ]]\n",
      "Loss: \n",
      " 0.0011838572910078564\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87512863]\n",
      " [0.84281815]\n",
      " [0.85528039]]\n",
      "Loss: \n",
      " 0.0011713690097647576\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87531075]\n",
      " [0.84301702]\n",
      " [0.85548   ]]\n",
      "Loss: \n",
      " 0.0011590602397639328\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87549134]\n",
      " [0.84321427]\n",
      " [0.85567797]]\n",
      "Loss: \n",
      " 0.0011469278955108543\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87567042]\n",
      " [0.8434099 ]\n",
      " [0.8558743 ]]\n",
      "Loss: \n",
      " 0.0011349689547544932\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.875848  ]\n",
      " [0.84360394]\n",
      " [0.85606901]]\n",
      "Loss: \n",
      " 0.0011231804569638044\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87602412]\n",
      " [0.84379641]\n",
      " [0.85626213]]\n",
      "Loss: \n",
      " 0.001111559501846675\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87619877]\n",
      " [0.84398733]\n",
      " [0.85645367]]\n",
      "Loss: \n",
      " 0.0011001032479098071\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87637198]\n",
      " [0.8441767 ]\n",
      " [0.85664365]]\n",
      "Loss: \n",
      " 0.0010888089110583467\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87654377]\n",
      " [0.84436455]\n",
      " [0.85683209]]\n",
      "Loss: \n",
      " 0.0010776737632340065\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87671415]\n",
      " [0.8445509 ]\n",
      " [0.857019  ]]\n",
      "Loss: \n",
      " 0.0010666951310904567\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87688314]\n",
      " [0.84473576]\n",
      " [0.85720441]]\n",
      "Loss: \n",
      " 0.0010558703947048573\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87705076]\n",
      " [0.84491915]\n",
      " [0.85738832]]\n",
      "Loss: \n",
      " 0.0010451969863243416\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87721701]\n",
      " [0.84510109]\n",
      " [0.85757076]]\n",
      "Loss: \n",
      " 0.0010346723891465298\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87738192]\n",
      " [0.84528159]\n",
      " [0.85775174]]\n",
      "Loss: \n",
      " 0.0010242941361328012\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8775455 ]\n",
      " [0.84546066]\n",
      " [0.85793129]]\n",
      "Loss: \n",
      " 0.001014059808853554\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87770776]\n",
      " [0.84563833]\n",
      " [0.8581094 ]]\n",
      "Loss: \n",
      " 0.0010039670363643156\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87786873]\n",
      " [0.8458146 ]\n",
      " [0.85828611]]\n",
      "Loss: \n",
      " 0.000994013494111856\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87802841]\n",
      " [0.8459895 ]\n",
      " [0.85846142]]\n",
      "Loss: \n",
      " 0.0009841969028693122\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87818681]\n",
      " [0.84616304]\n",
      " [0.85863536]]\n",
      "Loss: \n",
      " 0.0009745150276995561\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87834396]\n",
      " [0.84633522]\n",
      " [0.85880793]]\n",
      "Loss: \n",
      " 0.000964965676945874\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87849987]\n",
      " [0.84650608]\n",
      " [0.85897915]]\n",
      "Loss: \n",
      " 0.0009555467012491922\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87865454]\n",
      " [0.84667562]\n",
      " [0.85914904]]\n",
      "Loss: \n",
      " 0.0009462559925909822\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.878808  ]\n",
      " [0.84684385]\n",
      " [0.8593176 ]]\n",
      "Loss: \n",
      " 0.0009370914833612244\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87896026]\n",
      " [0.84701079]\n",
      " [0.85948486]]\n",
      "Loss: \n",
      " 0.0009280511454504804\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87911133]\n",
      " [0.84717645]\n",
      " [0.85965083]]\n",
      "Loss: \n",
      " 0.0009191329893656081\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87926122]\n",
      " [0.84734085]\n",
      " [0.85981552]]\n",
      "Loss: \n",
      " 0.0009103350633682059\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87940994]\n",
      " [0.847504  ]\n",
      " [0.85997895]]\n",
      "Loss: \n",
      " 0.0009016554526352576\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87955751]\n",
      " [0.84766592]\n",
      " [0.86014112]]\n",
      "Loss: \n",
      " 0.0008930922784412557\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87970395]\n",
      " [0.8478266 ]\n",
      " [0.86030206]]\n",
      "Loss: \n",
      " 0.0008846436973612752\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87984925]\n",
      " [0.84798608]\n",
      " [0.86046177]]\n",
      "Loss: \n",
      " 0.0008763079004942325\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87999344]\n",
      " [0.84814436]\n",
      " [0.86062027]]\n",
      "Loss: \n",
      " 0.0008680831127059114\n",
      "\n",
      "\n",
      "Epoch: 254\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88013653]\n",
      " [0.84830145]\n",
      " [0.86077757]]\n",
      "Loss: \n",
      " 0.0008599675918910919\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88027852]\n",
      " [0.84845736]\n",
      " [0.86093369]]\n",
      "Loss: \n",
      " 0.0008519596282542631\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88041943]\n",
      " [0.84861212]\n",
      " [0.86108863]]\n",
      "Loss: \n",
      " 0.0008440575436083489\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88055928]\n",
      " [0.84876572]\n",
      " [0.8612424 ]]\n",
      "Loss: \n",
      " 0.0008362596906910666\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88069806]\n",
      " [0.84891818]\n",
      " [0.86139503]]\n",
      "Loss: \n",
      " 0.00082856445249819\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8808358 ]\n",
      " [0.84906952]\n",
      " [0.86154652]]\n",
      "Loss: \n",
      " 0.0008209702416334816\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8809725 ]\n",
      " [0.84921974]\n",
      " [0.86169688]]\n",
      "Loss: \n",
      " 0.0008134754996746639\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88110818]\n",
      " [0.84936885]\n",
      " [0.86184612]]\n",
      "Loss: \n",
      " 0.000806078696555031\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88124284]\n",
      " [0.84951687]\n",
      " [0.86199426]]\n",
      "Loss: \n",
      " 0.0007987783299602658\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88137649]\n",
      " [0.84966381]\n",
      " [0.86214131]]\n",
      "Loss: \n",
      " 0.0007915729247400458\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88150915]\n",
      " [0.84980968]\n",
      " [0.86228728]]\n",
      "Loss: \n",
      " 0.0007844610323340115\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88164083]\n",
      " [0.84995448]\n",
      " [0.86243217]]\n",
      "Loss: \n",
      " 0.0007774412302116775\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88177153]\n",
      " [0.85009824]\n",
      " [0.862576  ]]\n",
      "Loss: \n",
      " 0.0007705121213259777\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88190127]\n",
      " [0.85024095]\n",
      " [0.86271879]]\n",
      "Loss: \n",
      " 0.0007636723335799778\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88203005]\n",
      " [0.85038263]\n",
      " [0.86286053]]\n",
      "Loss: \n",
      " 0.0007569205193064437\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88215789]\n",
      " [0.8505233 ]\n",
      " [0.86300125]]\n",
      "Loss: \n",
      " 0.0007502553547599298\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88228479]\n",
      " [0.85066295]\n",
      " [0.86314094]]\n",
      "Loss: \n",
      " 0.0007436755396210016\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88241076]\n",
      " [0.8508016 ]\n",
      " [0.86327963]]\n",
      "Loss: \n",
      " 0.0007371797965122877\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88253582]\n",
      " [0.85093926]\n",
      " [0.86341732]]\n",
      "Loss: \n",
      " 0.0007307668705260568\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88265997]\n",
      " [0.85107594]\n",
      " [0.86355402]]\n",
      "Loss: \n",
      " 0.000724435528762965\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88278322]\n",
      " [0.85121165]\n",
      " [0.86368974]]\n",
      "Loss: \n",
      " 0.0007181845598817144\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88290558]\n",
      " [0.8513464 ]\n",
      " [0.86382449]]\n",
      "Loss: \n",
      " 0.0007120127736593117\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88302706]\n",
      " [0.85148019]\n",
      " [0.86395827]]\n",
      "Loss: \n",
      " 0.0007059190005616701\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88314766]\n",
      " [0.85161304]\n",
      " [0.86409111]]\n",
      "Loss: \n",
      " 0.0006999020913242191\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8832674 ]\n",
      " [0.85174496]\n",
      " [0.86422301]]\n",
      "Loss: \n",
      " 0.0006939609165423043\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88338629]\n",
      " [0.85187595]\n",
      " [0.86435397]]\n",
      "Loss: \n",
      " 0.0006880943662711411\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88350432]\n",
      " [0.85200602]\n",
      " [0.86448401]]\n",
      "Loss: \n",
      " 0.0006823013496350011\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88362152]\n",
      " [0.85213518]\n",
      " [0.86461313]]\n",
      "Loss: \n",
      " 0.000676580794445449\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88373789]\n",
      " [0.85226344]\n",
      " [0.86474134]]\n",
      "Loss: \n",
      " 0.0006709316468283483\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88385343]\n",
      " [0.85239081]\n",
      " [0.86486866]]\n",
      "Loss: \n",
      " 0.0006653528708594505\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88396816]\n",
      " [0.8525173 ]\n",
      " [0.86499509]]\n",
      "Loss: \n",
      " 0.0006598434482083184\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88408207]\n",
      " [0.85264291]\n",
      " [0.86512063]]\n",
      "Loss: \n",
      " 0.0006544023777903607\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88419519]\n",
      " [0.85276766]\n",
      " [0.86524531]]\n",
      "Loss: \n",
      " 0.0006490286754267702\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88430752]\n",
      " [0.85289154]\n",
      " [0.86536911]]\n",
      "Loss: \n",
      " 0.0006437213735122255\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88441906]\n",
      " [0.85301457]\n",
      " [0.86549207]]\n",
      "Loss: \n",
      " 0.0006384795206900239\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88452982]\n",
      " [0.85313677]\n",
      " [0.86561417]]\n",
      "Loss: \n",
      " 0.0006333021815345938\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88463981]\n",
      " [0.85325812]\n",
      " [0.86573543]]\n",
      "Loss: \n",
      " 0.0006281884362411075\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88474904]\n",
      " [0.85337865]\n",
      " [0.86585586]]\n",
      "Loss: \n",
      " 0.0006231373803220591\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88485751]\n",
      " [0.85349836]\n",
      " [0.86597546]]\n",
      "Loss: \n",
      " 0.0006181481243106016\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88496523]\n",
      " [0.85361725]\n",
      " [0.86609425]]\n",
      "Loss: \n",
      " 0.000613219793470501\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88507221]\n",
      " [0.85373534]\n",
      " [0.86621222]]\n",
      "Loss: \n",
      " 0.0006083515275125182\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88517846]\n",
      " [0.85385263]\n",
      " [0.86632939]]\n",
      "Loss: \n",
      " 0.0006035424803170664\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88528398]\n",
      " [0.85396913]\n",
      " [0.86644577]]\n",
      "Loss: \n",
      " 0.0005987918196629738\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88538877]\n",
      " [0.85408484]\n",
      " [0.86656136]]\n",
      "Loss: \n",
      " 0.0005940987269622334\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88549285]\n",
      " [0.85419978]\n",
      " [0.86667616]]\n",
      "Loss: \n",
      " 0.0005894623970005539\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88559622]\n",
      " [0.85431395]\n",
      " [0.8667902 ]]\n",
      "Loss: \n",
      " 0.0005848820376835722\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88569889]\n",
      " [0.85442736]\n",
      " [0.86690346]]\n",
      "Loss: \n",
      " 0.0005803568697886207\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88580086]\n",
      " [0.85454   ]\n",
      " [0.86701596]]\n",
      "Loss: \n",
      " 0.0005758861267218615\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88590215]\n",
      " [0.8546519 ]\n",
      " [0.86712772]]\n",
      "Loss: \n",
      " 0.0005714690542807066\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88600275]\n",
      " [0.85476306]\n",
      " [0.86723872]]\n",
      "Loss: \n",
      " 0.0005671049104213375\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88610267]\n",
      " [0.85487348]\n",
      " [0.86734898]]\n",
      "Loss: \n",
      " 0.0005627929650312939\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88620192]\n",
      " [0.85498317]\n",
      " [0.86745851]]\n",
      "Loss: \n",
      " 0.0005585324997068485\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88630051]\n",
      " [0.85509213]\n",
      " [0.86756731]]\n",
      "Loss: \n",
      " 0.0005543228075352473\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88639843]\n",
      " [0.85520038]\n",
      " [0.8676754 ]]\n",
      "Loss: \n",
      " 0.0005501631928815383\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88649571]\n",
      " [0.85530792]\n",
      " [0.86778276]]\n",
      "Loss: \n",
      " 0.0005460529711799534\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88659233]\n",
      " [0.85541475]\n",
      " [0.86788942]]\n",
      "Loss: \n",
      " 0.0005419914687297299\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88668832]\n",
      " [0.85552088]\n",
      " [0.86799538]]\n",
      "Loss: \n",
      " 0.0005379780224952412\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88678366]\n",
      " [0.85562632]\n",
      " [0.86810064]]\n",
      "Loss: \n",
      " 0.0005340119799103344\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88687838]\n",
      " [0.85573107]\n",
      " [0.86820521]]\n",
      "Loss: \n",
      " 0.0005300926986868254\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88697247]\n",
      " [0.85583515]\n",
      " [0.8683091 ]]\n",
      "Loss: \n",
      " 0.0005262195466269618\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88706595]\n",
      " [0.85593854]\n",
      " [0.86841231]]\n",
      "Loss: \n",
      " 0.0005223919014398534\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8871588 ]\n",
      " [0.85604127]\n",
      " [0.86851485]]\n",
      "Loss: \n",
      " 0.000518609150561699\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88725105]\n",
      " [0.85614333]\n",
      " [0.86861672]]\n",
      "Loss: \n",
      " 0.0005148706909797931\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8873427 ]\n",
      " [0.85624474]\n",
      " [0.86871793]]\n",
      "Loss: \n",
      " 0.0005111759290601326\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88743375]\n",
      " [0.85634549]\n",
      " [0.86881849]]\n",
      "Loss: \n",
      " 0.0005075242803786361\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8875242 ]\n",
      " [0.8564456 ]\n",
      " [0.86891839]]\n",
      "Loss: \n",
      " 0.0005039151695558226\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88761407]\n",
      " [0.85654506]\n",
      " [0.86901765]]\n",
      "Loss: \n",
      " 0.0005003480300948926\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88770335]\n",
      " [0.85664389]\n",
      " [0.86911628]]\n",
      "Loss: \n",
      " 0.000496822304223159\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88779206]\n",
      " [0.85674208]\n",
      " [0.86921427]]\n",
      "Loss: \n",
      " 0.0004933374427366606\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88788019]\n",
      " [0.85683966]\n",
      " [0.86931163]]\n",
      "Loss: \n",
      " 0.0004898929048480202\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88796775]\n",
      " [0.85693661]\n",
      " [0.86940837]]\n",
      "Loss: \n",
      " 0.0004864881580373449\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88805475]\n",
      " [0.85703294]\n",
      " [0.8695045 ]]\n",
      "Loss: \n",
      " 0.0004831226779061899\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88814119]\n",
      " [0.85712867]\n",
      " [0.86960001]]\n",
      "Loss: \n",
      " 0.0004797959480344242\n",
      "\n",
      "\n",
      "Epoch: 327\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88822708]\n",
      " [0.85722379]\n",
      " [0.86969491]]\n",
      "Loss: \n",
      " 0.0004765074598400612\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88831242]\n",
      " [0.85731831]\n",
      " [0.86978922]]\n",
      "Loss: \n",
      " 0.0004732567124418418\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88839721]\n",
      " [0.85741223]\n",
      " [0.86988292]]\n",
      "Loss: \n",
      " 0.00047004321252462074\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88848146]\n",
      " [0.85750557]\n",
      " [0.86997604]]\n",
      "Loss: \n",
      " 0.00046686647420741663\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88856518]\n",
      " [0.85759831]\n",
      " [0.87006857]]\n",
      "Loss: \n",
      " 0.00046372601891412924\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88864837]\n",
      " [0.85769048]\n",
      " [0.87016051]]\n",
      "Loss: \n",
      " 0.0004606213752467879\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88873103]\n",
      " [0.85778207]\n",
      " [0.87025188]]\n",
      "Loss: \n",
      " 0.00045755207886136634\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88881316]\n",
      " [0.85787309]\n",
      " [0.87034267]]\n",
      "Loss: \n",
      " 0.0004545176723460182\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88889478]\n",
      " [0.85796355]\n",
      " [0.8704329 ]]\n",
      "Loss: \n",
      " 0.00045151770510174394\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88897589]\n",
      " [0.85805344]\n",
      " [0.87052256]]\n",
      "Loss: \n",
      " 0.0004485517332253897\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88905648]\n",
      " [0.85814277]\n",
      " [0.87061167]]\n",
      "Loss: \n",
      " 0.00044561931939495907\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88913657]\n",
      " [0.85823155]\n",
      " [0.87070022]]\n",
      "Loss: \n",
      " 0.00044272003275715074\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88921616]\n",
      " [0.85831979]\n",
      " [0.87078822]]\n",
      "Loss: \n",
      " 0.00043985344881714017\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88929525]\n",
      " [0.85840747]\n",
      " [0.87087568]]\n",
      "Loss: \n",
      " 0.00043701914933046046\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88937385]\n",
      " [0.85849462]\n",
      " [0.87096259]]\n",
      "Loss: \n",
      " 0.00043421672219700057\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88945196]\n",
      " [0.85858123]\n",
      " [0.87104897]]\n",
      "Loss: \n",
      " 0.00043144576135709345\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88952958]\n",
      " [0.85866731]\n",
      " [0.87113482]]\n",
      "Loss: \n",
      " 0.0004287058666895398\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88960672]\n",
      " [0.85875287]\n",
      " [0.87122013]]\n",
      "Loss: \n",
      " 0.0004259966439116943\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88968339]\n",
      " [0.8588379 ]\n",
      " [0.87130493]]\n",
      "Loss: \n",
      " 0.0004233177044813941\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88975958]\n",
      " [0.85892241]\n",
      " [0.8713892 ]]\n",
      "Loss: \n",
      " 0.00042066866550080937\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8898353 ]\n",
      " [0.8590064 ]\n",
      " [0.87147296]]\n",
      "Loss: \n",
      " 0.0004180491496221254\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88991056]\n",
      " [0.85908989]\n",
      " [0.87155621]]\n",
      "Loss: \n",
      " 0.000415458784955042\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88998535]\n",
      " [0.85917287]\n",
      " [0.87163895]]\n",
      "Loss: \n",
      " 0.00041289720497599463\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89005968]\n",
      " [0.85925534]\n",
      " [0.87172118]]\n",
      "Loss: \n",
      " 0.00041036404843915425\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89013356]\n",
      " [0.85933732]\n",
      " [0.87180292]]\n",
      "Loss: \n",
      " 0.00040785895928905323\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89020699]\n",
      " [0.8594188 ]\n",
      " [0.87188416]]\n",
      "Loss: \n",
      " 0.00040538158657493556\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89027997]\n",
      " [0.85949979]\n",
      " [0.87196491]]\n",
      "Loss: \n",
      " 0.00040293158436664777\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89035251]\n",
      " [0.85958029]\n",
      " [0.87204517]]\n",
      "Loss: \n",
      " 0.00040050861167216593\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8904246 ]\n",
      " [0.85966031]\n",
      " [0.87212495]]\n",
      "Loss: \n",
      " 0.00039811233235664763\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89049626]\n",
      " [0.85973984]\n",
      " [0.87220425]]\n",
      "Loss: \n",
      " 0.0003957424150629947\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89056748]\n",
      " [0.8598189 ]\n",
      " [0.87228307]]\n",
      "Loss: \n",
      " 0.0003933985331339299\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89063828]\n",
      " [0.85989749]\n",
      " [0.87236141]]\n",
      "Loss: \n",
      " 0.0003910803645354676\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89070864]\n",
      " [0.85997561]\n",
      " [0.87243929]]\n",
      "Loss: \n",
      " 0.00038878759178186784\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89077858]\n",
      " [0.86005327]\n",
      " [0.8725167 ]]\n",
      "Loss: \n",
      " 0.0003865199018619478\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8908481 ]\n",
      " [0.86013046]\n",
      " [0.87259365]]\n",
      "Loss: \n",
      " 0.00038427698616675483\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89091721]\n",
      " [0.86020719]\n",
      " [0.87267015]]\n",
      "Loss: \n",
      " 0.00038205854041858467\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8909859 ]\n",
      " [0.86028347]\n",
      " [0.87274618]]\n",
      "Loss: \n",
      " 0.0003798642646013031\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89105417]\n",
      " [0.86035929]\n",
      " [0.87282177]]\n",
      "Loss: \n",
      " 0.0003776938628919492\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89112204]\n",
      " [0.86043467]\n",
      " [0.8728969 ]]\n",
      "Loss: \n",
      " 0.0003755470435935769\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89118951]\n",
      " [0.8605096 ]\n",
      " [0.8729716 ]]\n",
      "Loss: \n",
      " 0.0003734235190693308\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89125657]\n",
      " [0.8605841 ]\n",
      " [0.87304585]]\n",
      "Loss: \n",
      " 0.0003713230056777454\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89132324]\n",
      " [0.86065815]\n",
      " [0.87311966]]\n",
      "Loss: \n",
      " 0.0003692452237091688\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89138951]\n",
      " [0.86073177]\n",
      " [0.87319304]]\n",
      "Loss: \n",
      " 0.0003671898973233966\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89145539]\n",
      " [0.86080495]\n",
      " [0.87326598]]\n",
      "Loss: \n",
      " 0.00036515675448839884\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89152087]\n",
      " [0.86087771]\n",
      " [0.8733385 ]]\n",
      "Loss: \n",
      " 0.0003631455269201506\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89158597]\n",
      " [0.86095004]\n",
      " [0.87341059]]\n",
      "Loss: \n",
      " 0.00036115595002358226\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89165069]\n",
      " [0.86102195]\n",
      " [0.87348226]]\n",
      "Loss: \n",
      " 0.00035918776283454186\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89171503]\n",
      " [0.86109344]\n",
      " [0.87355352]]\n",
      "Loss: \n",
      " 0.0003572407079628248\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89177899]\n",
      " [0.86116452]\n",
      " [0.87362435]]\n",
      "Loss: \n",
      " 0.0003553145315362244\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89184257]\n",
      " [0.86123518]\n",
      " [0.87369477]]\n",
      "Loss: \n",
      " 0.00035340898314558175\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89190578]\n",
      " [0.86130543]\n",
      " [0.87376479]]\n",
      "Loss: \n",
      " 0.00035152381579078287\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89196862]\n",
      " [0.86137527]\n",
      " [0.8738344 ]]\n",
      "Loss: \n",
      " 0.0003496587858277556\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8920311 ]\n",
      " [0.86144471]\n",
      " [0.8739036 ]]\n",
      "Loss: \n",
      " 0.00034781365291637503\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89209321]\n",
      " [0.86151375]\n",
      " [0.8739724 ]]\n",
      "Loss: \n",
      " 0.000345988179969306\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89215495]\n",
      " [0.86158239]\n",
      " [0.87404081]]\n",
      "Loss: \n",
      " 0.0003441821331017513\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89221634]\n",
      " [0.86165064]\n",
      " [0.87410882]]\n",
      "Loss: \n",
      " 0.0003423952815820542\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89227738]\n",
      " [0.86171849]\n",
      " [0.87417644]]\n",
      "Loss: \n",
      " 0.0003406273977832116\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89233806]\n",
      " [0.86178596]\n",
      " [0.87424367]]\n",
      "Loss: \n",
      " 0.0003388782571351896\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89239839]\n",
      " [0.86185303]\n",
      " [0.87431051]]\n",
      "Loss: \n",
      " 0.00033714763807811713\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89245837]\n",
      " [0.86191973]\n",
      " [0.87437697]]\n",
      "Loss: \n",
      " 0.0003354353220162562\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.892518  ]\n",
      " [0.86198604]\n",
      " [0.87444305]]\n",
      "Loss: \n",
      " 0.0003337410932728058\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89257729]\n",
      " [0.86205197]\n",
      " [0.87450875]]\n",
      "Loss: \n",
      " 0.0003320647390454563\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89263624]\n",
      " [0.86211753]\n",
      " [0.87457408]]\n",
      "Loss: \n",
      " 0.000330406049362748\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89269486]\n",
      " [0.86218271]\n",
      " [0.87463903]]\n",
      "Loss: \n",
      " 0.00032876481704114703\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89275313]\n",
      " [0.86224752]\n",
      " [0.87470361]]\n",
      "Loss: \n",
      " 0.0003271408376429032\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89281108]\n",
      " [0.86231197]\n",
      " [0.87476783]]\n",
      "Loss: \n",
      " 0.00032553390943459163\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89286869]\n",
      " [0.86237605]\n",
      " [0.87483168]]\n",
      "Loss: \n",
      " 0.00032394383334638467\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89292597]\n",
      " [0.86243977]\n",
      " [0.87489517]]\n",
      "Loss: \n",
      " 0.0003223704129320301\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89298293]\n",
      " [0.86250312]\n",
      " [0.87495831]]\n",
      "Loss: \n",
      " 0.00032081345432948753\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89303956]\n",
      " [0.86256612]\n",
      " [0.87502108]]\n",
      "Loss: \n",
      " 0.00031927276622226923\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89309587]\n",
      " [0.86262877]\n",
      " [0.8750835 ]]\n",
      "Loss: \n",
      " 0.00031774815980139675\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89315186]\n",
      " [0.86269106]\n",
      " [0.87514557]]\n",
      "Loss: \n",
      " 0.00031623944872805125\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89320754]\n",
      " [0.862753  ]\n",
      " [0.87520729]]\n",
      "Loss: \n",
      " 0.0003147464490968021\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8932629 ]\n",
      " [0.86281459]\n",
      " [0.87526866]]\n",
      "Loss: \n",
      " 0.00031326897939950655\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89331795]\n",
      " [0.86287584]\n",
      " [0.87532969]]\n",
      "Loss: \n",
      " 0.00031180686048979197\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89337268]\n",
      " [0.86293675]\n",
      " [0.87539037]]\n",
      "Loss: \n",
      " 0.00031035991554813244\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89342711]\n",
      " [0.86299731]\n",
      " [0.87545072]]\n",
      "Loss: \n",
      " 0.000308927970047523\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89348123]\n",
      " [0.86305754]\n",
      " [0.87551073]]\n",
      "Loss: \n",
      " 0.00030751085171972794\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89353505]\n",
      " [0.86311743]\n",
      " [0.8755704 ]]\n",
      "Loss: \n",
      " 0.00030610839052208166\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89358857]\n",
      " [0.86317699]\n",
      " [0.87562974]]\n",
      "Loss: \n",
      " 0.00030472041860485686\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89364179]\n",
      " [0.86323621]\n",
      " [0.87568875]]\n",
      "Loss: \n",
      " 0.00030334677027916995\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89369471]\n",
      " [0.86329511]\n",
      " [0.87574743]]\n",
      "Loss: \n",
      " 0.0003019872819854177\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89374733]\n",
      " [0.86335368]\n",
      " [0.87580579]]\n",
      "Loss: \n",
      " 0.0003006417922622368\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89379966]\n",
      " [0.86341193]\n",
      " [0.87586383]]\n",
      "Loss: \n",
      " 0.00029931014171597343\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8938517 ]\n",
      " [0.86346985]\n",
      " [0.87592154]]\n",
      "Loss: \n",
      " 0.00029799217299067383\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89390345]\n",
      " [0.86352745]\n",
      " [0.87597893]]\n",
      "Loss: \n",
      " 0.0002966877307385446\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89395491]\n",
      " [0.86358474]\n",
      " [0.87603601]]\n",
      "Loss: \n",
      " 0.00029539666159091694\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89400609]\n",
      " [0.86364171]\n",
      " [0.87609277]]\n",
      "Loss: \n",
      " 0.00029411881412966435\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89405698]\n",
      " [0.86369837]\n",
      " [0.87614922]]\n",
      "Loss: \n",
      " 0.0002928540388591251\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8941076 ]\n",
      " [0.86375471]\n",
      " [0.87620536]]\n",
      "Loss: \n",
      " 0.0002916021881784464\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89415793]\n",
      " [0.86381075]\n",
      " [0.87626119]]\n",
      "Loss: \n",
      " 0.00029036311635439874\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89420798]\n",
      " [0.86386647]\n",
      " [0.87631672]]\n",
      "Loss: \n",
      " 0.0002891366794946207\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89425776]\n",
      " [0.8639219 ]\n",
      " [0.87637194]]\n",
      "Loss: \n",
      " 0.0002879227355213082\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89430727]\n",
      " [0.86397702]\n",
      " [0.87642686]]\n",
      "Loss: \n",
      " 0.0002867211441453283\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8943565 ]\n",
      " [0.86403184]\n",
      " [0.87648147]]\n",
      "Loss: \n",
      " 0.0002855317668407434\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89440546]\n",
      " [0.86408636]\n",
      " [0.87653579]]\n",
      "Loss: \n",
      " 0.0002843544668197626\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89445416]\n",
      " [0.86414058]\n",
      " [0.87658982]]\n",
      "Loss: \n",
      " 0.00028318910900805935\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89450259]\n",
      " [0.8641945 ]\n",
      " [0.87664355]]\n",
      "Loss: \n",
      " 0.0002820355600205281\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89455075]\n",
      " [0.86424814]\n",
      " [0.87669699]]\n",
      "Loss: \n",
      " 0.000280893688137425\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89459865]\n",
      " [0.86430148]\n",
      " [0.87675014]]\n",
      "Loss: \n",
      " 0.0002797633632808443\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89464629]\n",
      " [0.86435453]\n",
      " [0.876803  ]]\n",
      "Loss: \n",
      " 0.0002786444569916287\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89469367]\n",
      " [0.8644073 ]\n",
      " [0.87685557]]\n",
      "Loss: \n",
      " 0.00027753684240661283\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89474079]\n",
      " [0.86445978]\n",
      " [0.87690786]]\n",
      "Loss: \n",
      " 0.0002764403942362305\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89478766]\n",
      " [0.86451198]\n",
      " [0.87695987]]\n",
      "Loss: \n",
      " 0.0002753549887424956\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89483427]\n",
      " [0.86456389]\n",
      " [0.8770116 ]]\n",
      "Loss: \n",
      " 0.000274280503717311\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89488063]\n",
      " [0.86461553]\n",
      " [0.87706305]]\n",
      "Loss: \n",
      " 0.0002732168184611334\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89492674]\n",
      " [0.86466688]\n",
      " [0.87711422]]\n",
      "Loss: \n",
      " 0.000272163813761967\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8949726 ]\n",
      " [0.86471797]\n",
      " [0.87716511]]\n",
      "Loss: \n",
      " 0.000271121371874686\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89501822]\n",
      " [0.86476877]\n",
      " [0.87721574]]\n",
      "Loss: \n",
      " 0.00027008937650070496\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89506358]\n",
      " [0.86481931]\n",
      " [0.87726609]]\n",
      "Loss: \n",
      " 0.00026906771276791923\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8951087 ]\n",
      " [0.86486957]\n",
      " [0.87731617]]\n",
      "Loss: \n",
      " 0.00026805626721101354\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89515358]\n",
      " [0.86491956]\n",
      " [0.87736599]]\n",
      "Loss: \n",
      " 0.00026705492775204285\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89519822]\n",
      " [0.86496929]\n",
      " [0.87741553]]\n",
      "Loss: \n",
      " 0.0002660635836813341\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89524262]\n",
      " [0.86501875]\n",
      " [0.87746482]]\n",
      "Loss: \n",
      " 0.00026508212563866373\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89528678]\n",
      " [0.86506794]\n",
      " [0.87751384]]\n",
      "Loss: \n",
      " 0.0002641104455947558\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89533071]\n",
      " [0.86511688]\n",
      " [0.8775626 ]]\n",
      "Loss: \n",
      " 0.0002631484368330333\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8953744 ]\n",
      " [0.86516555]\n",
      " [0.8776111 ]]\n",
      "Loss: \n",
      " 0.0002621959939316892\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89541786]\n",
      " [0.86521397]\n",
      " [0.87765934]]\n",
      "Loss: \n",
      " 0.00026125301274600876\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89546108]\n",
      " [0.86526213]\n",
      " [0.87770733]]\n",
      "Loss: \n",
      " 0.0002603193903909625\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89550408]\n",
      " [0.86531003]\n",
      " [0.87775506]]\n",
      "Loss: \n",
      " 0.0002593950252240754\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89554684]\n",
      " [0.86535768]\n",
      " [0.87780255]]\n",
      "Loss: \n",
      " 0.00025847981682856566\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89558938]\n",
      " [0.86540507]\n",
      " [0.87784977]]\n",
      "Loss: \n",
      " 0.0002575736659967334\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8956317 ]\n",
      " [0.86545222]\n",
      " [0.87789676]]\n",
      "Loss: \n",
      " 0.0002566764747135942\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89567379]\n",
      " [0.86549911]\n",
      " [0.87794349]]\n",
      "Loss: \n",
      " 0.00025578814614077316\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89571565]\n",
      " [0.86554576]\n",
      " [0.87798997]]\n",
      "Loss: \n",
      " 0.0002549085846006505\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8957573 ]\n",
      " [0.86559216]\n",
      " [0.87803622]]\n",
      "Loss: \n",
      " 0.000254037695560741\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89579872]\n",
      " [0.86563832]\n",
      " [0.87808221]]\n",
      "Loss: \n",
      " 0.00025317538561828797\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89583993]\n",
      " [0.86568424]\n",
      " [0.87812797]]\n",
      "Loss: \n",
      " 0.0002523215624851453\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89588092]\n",
      " [0.86572991]\n",
      " [0.87817349]]\n",
      "Loss: \n",
      " 0.00025147613497282024\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89592169]\n",
      " [0.86577534]\n",
      " [0.87821877]]\n",
      "Loss: \n",
      " 0.0002506390129778026\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89596225]\n",
      " [0.86582054]\n",
      " [0.87826381]]\n",
      "Loss: \n",
      " 0.0002498101074670724\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8960026 ]\n",
      " [0.8658655 ]\n",
      " [0.87830861]]\n",
      "Loss: \n",
      " 0.0002489893304638461\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89604273]\n",
      " [0.86591022]\n",
      " [0.87835319]]\n",
      "Loss: \n",
      " 0.0002481765950335351\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89608265]\n",
      " [0.86595471]\n",
      " [0.87839753]]\n",
      "Loss: \n",
      " 0.0002473718152698966\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89612237]\n",
      " [0.86599897]\n",
      " [0.87844164]]\n",
      "Loss: \n",
      " 0.00024657490628142854\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89616187]\n",
      " [0.86604299]\n",
      " [0.87848551]]\n",
      "Loss: \n",
      " 0.00024578578417791265\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89620118]\n",
      " [0.86608679]\n",
      " [0.87852917]]\n",
      "Loss: \n",
      " 0.0002450043660572273\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89624027]\n",
      " [0.86613036]\n",
      " [0.87857259]]\n",
      "Loss: \n",
      " 0.0002442305699922888\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89627916]\n",
      " [0.8661737 ]\n",
      " [0.87861579]]\n",
      "Loss: \n",
      " 0.0002434643150182181\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89631785]\n",
      " [0.86621682]\n",
      " [0.87865876]]\n",
      "Loss: \n",
      " 0.00024270552111971822\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89635634]\n",
      " [0.86625971]\n",
      " [0.87870152]]\n",
      "Loss: \n",
      " 0.00024195410921858682\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89639463]\n",
      " [0.86630238]\n",
      " [0.87874405]]\n",
      "Loss: \n",
      " 0.0002412100011614651\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89643272]\n",
      " [0.86634483]\n",
      " [0.87878636]]\n",
      "Loss: \n",
      " 0.00024047311970771648\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89647061]\n",
      " [0.86638706]\n",
      " [0.87882845]]\n",
      "Loss: \n",
      " 0.00023974338851754967\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89650831]\n",
      " [0.86642907]\n",
      " [0.87887033]]\n",
      "Loss: \n",
      " 0.00023902073214022946\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89654581]\n",
      " [0.86647086]\n",
      " [0.87891199]]\n",
      "Loss: \n",
      " 0.00023830507600254949\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89658311]\n",
      " [0.86651244]\n",
      " [0.87895344]]\n",
      "Loss: \n",
      " 0.00023759634639739367\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89662023]\n",
      " [0.86655381]\n",
      " [0.87899467]]\n",
      "Loss: \n",
      " 0.00023689447047254165\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89665715]\n",
      " [0.86659496]\n",
      " [0.87903569]]\n",
      "Loss: \n",
      " 0.00023619937621956262\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89669388]\n",
      " [0.8666359 ]\n",
      " [0.8790765 ]]\n",
      "Loss: \n",
      " 0.0002355109924629258\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89673043]\n",
      " [0.86667662]\n",
      " [0.87911711]]\n",
      "Loss: \n",
      " 0.00023482924884924423\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89676678]\n",
      " [0.86671714]\n",
      " [0.8791575 ]]\n",
      "Loss: \n",
      " 0.00023415407583667554\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89680295]\n",
      " [0.86675746]\n",
      " [0.87919769]]\n",
      "Loss: \n",
      " 0.0002334854046844776\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89683893]\n",
      " [0.86679756]\n",
      " [0.87923767]]\n",
      "Loss: \n",
      " 0.00023282316744273378\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89687473]\n",
      " [0.86683746]\n",
      " [0.87927745]]\n",
      "Loss: \n",
      " 0.0002321672969421881\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89691035]\n",
      " [0.86687715]\n",
      " [0.87931703]]\n",
      "Loss: \n",
      " 0.0002315177267842508\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89694578]\n",
      " [0.86691665]\n",
      " [0.8793564 ]]\n",
      "Loss: \n",
      " 0.00023087439133116406\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89698103]\n",
      " [0.86695594]\n",
      " [0.87939557]]\n",
      "Loss: \n",
      " 0.00023023722569626877\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89701611]\n",
      " [0.86699503]\n",
      " [0.87943455]]\n",
      "Loss: \n",
      " 0.00022960616573443565\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.897051  ]\n",
      " [0.86703392]\n",
      " [0.87947332]]\n",
      "Loss: \n",
      " 0.0002289811480326307\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89708572]\n",
      " [0.86707261]\n",
      " [0.8795119 ]]\n",
      "Loss: \n",
      " 0.00022836210990061426\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89712026]\n",
      " [0.8671111 ]\n",
      " [0.87955029]]\n",
      "Loss: \n",
      " 0.0002277489893617689\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89715462]\n",
      " [0.8671494 ]\n",
      " [0.87958848]]\n",
      "Loss: \n",
      " 0.00022714172514406118\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89718881]\n",
      " [0.86718751]\n",
      " [0.87962648]]\n",
      "Loss: \n",
      " 0.00022654025667112244\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89722282]\n",
      " [0.86722542]\n",
      " [0.87966428]]\n",
      "Loss: \n",
      " 0.0002259445240534781\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89725667]\n",
      " [0.86726314]\n",
      " [0.87970189]]\n",
      "Loss: \n",
      " 0.00022535446807987834\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89729034]\n",
      " [0.86730067]\n",
      " [0.87973932]]\n",
      "Loss: \n",
      " 0.00022477003020875545\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89732384]\n",
      " [0.867338  ]\n",
      " [0.87977655]]\n",
      "Loss: \n",
      " 0.00022419115255981203\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89735717]\n",
      " [0.86737515]\n",
      " [0.8798136 ]]\n",
      "Loss: \n",
      " 0.00022361777790572384\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89739033]\n",
      " [0.86741211]\n",
      " [0.87985046]]\n",
      "Loss: \n",
      " 0.00022304984966394276\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89742333]\n",
      " [0.86744889]\n",
      " [0.87988714]]\n",
      "Loss: \n",
      " 0.0002224873118886497\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89745616]\n",
      " [0.86748548]\n",
      " [0.87992363]]\n",
      "Loss: \n",
      " 0.00022193010926277053\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89748882]\n",
      " [0.86752188]\n",
      " [0.87995994]]\n",
      "Loss: \n",
      " 0.00022137818709016852\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89752132]\n",
      " [0.8675581 ]\n",
      " [0.87999607]]\n",
      "Loss: \n",
      " 0.00022083149128786334\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89755366]\n",
      " [0.86759414]\n",
      " [0.88003202]]\n",
      "Loss: \n",
      " 0.00022028996837845048\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89758583]\n",
      " [0.86763   ]\n",
      " [0.88006778]]\n",
      "Loss: \n",
      " 0.00021975356548254398\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89761785]\n",
      " [0.86766568]\n",
      " [0.88010337]]\n",
      "Loss: \n",
      " 0.00021922223031137797\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8976497 ]\n",
      " [0.86770118]\n",
      " [0.88013878]]\n",
      "Loss: \n",
      " 0.00021869591115949093\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89768139]\n",
      " [0.8677365 ]\n",
      " [0.88017401]]\n",
      "Loss: \n",
      " 0.00021817455689751176\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89771293]\n",
      " [0.86777164]\n",
      " [0.88020907]]\n",
      "Loss: \n",
      " 0.00021765811696503352\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8977443 ]\n",
      " [0.86780661]\n",
      " [0.88024395]]\n",
      "Loss: \n",
      " 0.0002171465413636195\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89777552]\n",
      " [0.8678414 ]\n",
      " [0.88027866]]\n",
      "Loss: \n",
      " 0.00021663978064987376\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89780659]\n",
      " [0.86787602]\n",
      " [0.8803132 ]]\n",
      "Loss: \n",
      " 0.00021613778592860985\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8978375 ]\n",
      " [0.86791046]\n",
      " [0.88034757]]\n",
      "Loss: \n",
      " 0.00021564050884613983\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89786825]\n",
      " [0.86794474]\n",
      " [0.88038176]]\n",
      "Loss: \n",
      " 0.0002151479015836212\n",
      "\n",
      "\n",
      "Epoch: 512\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89789885]\n",
      " [0.86797884]\n",
      " [0.88041579]]\n",
      "Loss: \n",
      " 0.00021465991685051494\n",
      "\n",
      "\n",
      "Epoch: 513\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8979293 ]\n",
      " [0.86801277]\n",
      " [0.88044964]]\n",
      "Loss: \n",
      " 0.0002141765078781245\n",
      "\n",
      "\n",
      "Epoch: 514\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8979596 ]\n",
      " [0.86804654]\n",
      " [0.88048333]]\n",
      "Loss: \n",
      " 0.00021369762841323646\n",
      "\n",
      "\n",
      "Epoch: 515\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89798975]\n",
      " [0.86808013]\n",
      " [0.88051686]]\n",
      "Loss: \n",
      " 0.0002132232327118249\n",
      "\n",
      "\n",
      "Epoch: 516\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89801975]\n",
      " [0.86811356]\n",
      " [0.88055021]]\n",
      "Loss: \n",
      " 0.00021275327553286152\n",
      "\n",
      "\n",
      "Epoch: 517\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8980496 ]\n",
      " [0.86814682]\n",
      " [0.8805834 ]]\n",
      "Loss: \n",
      " 0.00021228771213220167\n",
      "\n",
      "\n",
      "Epoch: 518\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8980793 ]\n",
      " [0.86817992]\n",
      " [0.88061643]]\n",
      "Loss: \n",
      " 0.00021182649825655548\n",
      "\n",
      "\n",
      "Epoch: 519\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89810886]\n",
      " [0.86821285]\n",
      " [0.8806493 ]]\n",
      "Loss: \n",
      " 0.00021136959013753093\n",
      "\n",
      "\n",
      "Epoch: 520\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89813827]\n",
      " [0.86824562]\n",
      " [0.880682  ]]\n",
      "Loss: \n",
      " 0.00021091694448577224\n",
      "\n",
      "\n",
      "Epoch: 521\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89816753]\n",
      " [0.86827823]\n",
      " [0.88071455]]\n",
      "Loss: \n",
      " 0.000210468518485172\n",
      "\n",
      "\n",
      "Epoch: 522\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89819665]\n",
      " [0.86831068]\n",
      " [0.88074693]]\n",
      "Loss: \n",
      " 0.00021002426978715015\n",
      "\n",
      "\n",
      "Epoch: 523\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89822563]\n",
      " [0.86834296]\n",
      " [0.88077915]]\n",
      "Loss: \n",
      " 0.00020958415650502958\n",
      "\n",
      "\n",
      "Epoch: 524\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89825446]\n",
      " [0.86837509]\n",
      " [0.88081122]]\n",
      "Loss: \n",
      " 0.00020914813720848178\n",
      "\n",
      "\n",
      "Epoch: 525\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89828315]\n",
      " [0.86840706]\n",
      " [0.88084313]]\n",
      "Loss: \n",
      " 0.0002087161709180115\n",
      "\n",
      "\n",
      "Epoch: 526\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8983117 ]\n",
      " [0.86843887]\n",
      " [0.88087488]]\n",
      "Loss: \n",
      " 0.00020828821709958985\n",
      "\n",
      "\n",
      "Epoch: 527\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89834011]\n",
      " [0.86847052]\n",
      " [0.88090648]]\n",
      "Loss: \n",
      " 0.00020786423565927488\n",
      "\n",
      "\n",
      "Epoch: 528\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89836838]\n",
      " [0.86850202]\n",
      " [0.88093792]]\n",
      "Loss: \n",
      " 0.00020744418693797244\n",
      "\n",
      "\n",
      "Epoch: 529\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89839651]\n",
      " [0.86853336]\n",
      " [0.88096921]]\n",
      "Loss: \n",
      " 0.00020702803170622317\n",
      "\n",
      "\n",
      "Epoch: 530\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89842451]\n",
      " [0.86856455]\n",
      " [0.88100034]]\n",
      "Loss: \n",
      " 0.00020661573115908299\n",
      "\n",
      "\n",
      "Epoch: 531\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89845237]\n",
      " [0.86859559]\n",
      " [0.88103133]]\n",
      "Loss: \n",
      " 0.0002062072469110476\n",
      "\n",
      "\n",
      "Epoch: 532\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89848009]\n",
      " [0.86862647]\n",
      " [0.88106216]]\n",
      "Loss: \n",
      " 0.0002058025409910761\n",
      "\n",
      "\n",
      "Epoch: 533\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89850767]\n",
      " [0.8686572 ]\n",
      " [0.88109284]]\n",
      "Loss: \n",
      " 0.0002054015758376628\n",
      "\n",
      "\n",
      "Epoch: 534\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89853512]\n",
      " [0.86868778]\n",
      " [0.88112338]]\n",
      "Loss: \n",
      " 0.00020500431429395583\n",
      "\n",
      "\n",
      "Epoch: 535\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89856244]\n",
      " [0.86871821]\n",
      " [0.88115376]]\n",
      "Loss: \n",
      " 0.00020461071960298344\n",
      "\n",
      "\n",
      "Epoch: 536\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89858962]\n",
      " [0.86874849]\n",
      " [0.881184  ]]\n",
      "Loss: \n",
      " 0.00020422075540289897\n",
      "\n",
      "\n",
      "Epoch: 537\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89861667]\n",
      " [0.86877863]\n",
      " [0.88121409]]\n",
      "Loss: \n",
      " 0.0002038343857223199\n",
      "\n",
      "\n",
      "Epoch: 538\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89864359]\n",
      " [0.86880861]\n",
      " [0.88124403]]\n",
      "Loss: \n",
      " 0.00020345157497572282\n",
      "\n",
      "\n",
      "Epoch: 539\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89867038]\n",
      " [0.86883845]\n",
      " [0.88127383]]\n",
      "Loss: \n",
      " 0.00020307228795887126\n",
      "\n",
      "\n",
      "Epoch: 540\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89869704]\n",
      " [0.86886814]\n",
      " [0.88130348]]\n",
      "Loss: \n",
      " 0.00020269648984433796\n",
      "\n",
      "\n",
      "Epoch: 541\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89872357]\n",
      " [0.86889769]\n",
      " [0.88133299]]\n",
      "Loss: \n",
      " 0.00020232414617708092\n",
      "\n",
      "\n",
      "Epoch: 542\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89874997]\n",
      " [0.8689271 ]\n",
      " [0.88136236]]\n",
      "Loss: \n",
      " 0.00020195522287004918\n",
      "\n",
      "\n",
      "Epoch: 543\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89877624]\n",
      " [0.86895636]\n",
      " [0.88139159]]\n",
      "Loss: \n",
      " 0.00020158968619988254\n",
      "\n",
      "\n",
      "Epoch: 544\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89880239]\n",
      " [0.86898548]\n",
      " [0.88142067]]\n",
      "Loss: \n",
      " 0.00020122750280263712\n",
      "\n",
      "\n",
      "Epoch: 545\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8988284 ]\n",
      " [0.86901445]\n",
      " [0.88144962]]\n",
      "Loss: \n",
      " 0.00020086863966958836\n",
      "\n",
      "\n",
      "Epoch: 546\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8988543 ]\n",
      " [0.86904329]\n",
      " [0.88147842]]\n",
      "Loss: \n",
      " 0.000200513064143076\n",
      "\n",
      "\n",
      "Epoch: 547\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89888006]\n",
      " [0.86907199]\n",
      " [0.88150709]]\n",
      "Loss: \n",
      " 0.0002001607439124042\n",
      "\n",
      "\n",
      "Epoch: 548\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89890571]\n",
      " [0.86910054]\n",
      " [0.88153562]]\n",
      "Loss: \n",
      " 0.00019981164700980463\n",
      "\n",
      "\n",
      "Epoch: 549\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89893122]\n",
      " [0.86912896]\n",
      " [0.88156401]]\n",
      "Loss: \n",
      " 0.00019946574180643452\n",
      "\n",
      "\n",
      "Epoch: 550\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89895662]\n",
      " [0.86915724]\n",
      " [0.88159226]]\n",
      "Loss: \n",
      " 0.00019912299700844513\n",
      "\n",
      "\n",
      "Epoch: 551\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89898189]\n",
      " [0.86918539]\n",
      " [0.88162038]]\n",
      "Loss: \n",
      " 0.00019878338165308022\n",
      "\n",
      "\n",
      "Epoch: 552\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89900704]\n",
      " [0.86921339]\n",
      " [0.88164836]]\n",
      "Loss: \n",
      " 0.0001984468651048495\n",
      "\n",
      "\n",
      "Epoch: 553\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89903207]\n",
      " [0.86924126]\n",
      " [0.88167621]]\n",
      "Loss: \n",
      " 0.0001981134170517268\n",
      "\n",
      "\n",
      "Epoch: 554\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89905699]\n",
      " [0.869269  ]\n",
      " [0.88170393]]\n",
      "Loss: \n",
      " 0.0001977830075014165\n",
      "\n",
      "\n",
      "Epoch: 555\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89908178]\n",
      " [0.8692966 ]\n",
      " [0.88173151]]\n",
      "Loss: \n",
      " 0.00019745560677765237\n",
      "\n",
      "\n",
      "Epoch: 556\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89910645]\n",
      " [0.86932407]\n",
      " [0.88175896]]\n",
      "Loss: \n",
      " 0.00019713118551655442\n",
      "\n",
      "\n",
      "Epoch: 557\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.899131  ]\n",
      " [0.86935141]\n",
      " [0.88178628]]\n",
      "Loss: \n",
      " 0.00019680971466302675\n",
      "\n",
      "\n",
      "Epoch: 558\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89915544]\n",
      " [0.86937861]\n",
      " [0.88181347]]\n",
      "Loss: \n",
      " 0.00019649116546720312\n",
      "\n",
      "\n",
      "Epoch: 559\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89917975]\n",
      " [0.86940569]\n",
      " [0.88184053]]\n",
      "Loss: \n",
      " 0.00019617550948094844\n",
      "\n",
      "\n",
      "Epoch: 560\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89920396]\n",
      " [0.86943263]\n",
      " [0.88186746]]\n",
      "Loss: \n",
      " 0.00019586271855437265\n",
      "\n",
      "\n",
      "Epoch: 561\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89922804]\n",
      " [0.86945944]\n",
      " [0.88189426]]\n",
      "Loss: \n",
      " 0.00019555276483242777\n",
      "\n",
      "\n",
      "Epoch: 562\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89925201]\n",
      " [0.86948613]\n",
      " [0.88192094]]\n",
      "Loss: \n",
      " 0.00019524562075152552\n",
      "\n",
      "\n",
      "Epoch: 563\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89927587]\n",
      " [0.86951268]\n",
      " [0.88194748]]\n",
      "Loss: \n",
      " 0.0001949412590362004\n",
      "\n",
      "\n",
      "Epoch: 564\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89929961]\n",
      " [0.86953911]\n",
      " [0.8819739 ]]\n",
      "Loss: \n",
      " 0.00019463965269582296\n",
      "\n",
      "\n",
      "Epoch: 565\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89932324]\n",
      " [0.86956541]\n",
      " [0.8820002 ]]\n",
      "Loss: \n",
      " 0.00019434077502134394\n",
      "\n",
      "\n",
      "Epoch: 566\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89934676]\n",
      " [0.86959159]\n",
      " [0.88202637]]\n",
      "Loss: \n",
      " 0.00019404459958209013\n",
      "\n",
      "\n",
      "Epoch: 567\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89937016]\n",
      " [0.86961764]\n",
      " [0.88205241]]\n",
      "Loss: \n",
      " 0.0001937511002225868\n",
      "\n",
      "\n",
      "Epoch: 568\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89939346]\n",
      " [0.86964356]\n",
      " [0.88207833]]\n",
      "Loss: \n",
      " 0.00019346025105943518\n",
      "\n",
      "\n",
      "Epoch: 569\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89941664]\n",
      " [0.86966936]\n",
      " [0.88210413]]\n",
      "Loss: \n",
      " 0.00019317202647822177\n",
      "\n",
      "\n",
      "Epoch: 570\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89943971]\n",
      " [0.86969504]\n",
      " [0.88212981]]\n",
      "Loss: \n",
      " 0.00019288640113046852\n",
      "\n",
      "\n",
      "Epoch: 571\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89946267]\n",
      " [0.86972059]\n",
      " [0.88215536]]\n",
      "Loss: \n",
      " 0.00019260334993060808\n",
      "\n",
      "\n",
      "Epoch: 572\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89948553]\n",
      " [0.86974602]\n",
      " [0.8821808 ]]\n",
      "Loss: \n",
      " 0.00019232284805302505\n",
      "\n",
      "\n",
      "Epoch: 573\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89950827]\n",
      " [0.86977133]\n",
      " [0.88220611]]\n",
      "Loss: \n",
      " 0.00019204487092910782\n",
      "\n",
      "\n",
      "Epoch: 574\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89953091]\n",
      " [0.86979652]\n",
      " [0.8822313 ]]\n",
      "Loss: \n",
      " 0.00019176939424434998\n",
      "\n",
      "\n",
      "Epoch: 575\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89955344]\n",
      " [0.86982159]\n",
      " [0.88225638]]\n",
      "Loss: \n",
      " 0.0001914963939354808\n",
      "\n",
      "\n",
      "Epoch: 576\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89957586]\n",
      " [0.86984654]\n",
      " [0.88228133]]\n",
      "Loss: \n",
      " 0.00019122584618763892\n",
      "\n",
      "\n",
      "Epoch: 577\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89959818]\n",
      " [0.86987137]\n",
      " [0.88230617]]\n",
      "Loss: \n",
      " 0.00019095772743157926\n",
      "\n",
      "\n",
      "Epoch: 578\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89962039]\n",
      " [0.86989608]\n",
      " [0.88233089]]\n",
      "Loss: \n",
      " 0.00019069201434091218\n",
      "\n",
      "\n",
      "Epoch: 579\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8996425 ]\n",
      " [0.86992068]\n",
      " [0.8823555 ]]\n",
      "Loss: \n",
      " 0.0001904286838293694\n",
      "\n",
      "\n",
      "Epoch: 580\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8996645 ]\n",
      " [0.86994516]\n",
      " [0.88237999]]\n",
      "Loss: \n",
      " 0.00019016771304812766\n",
      "\n",
      "\n",
      "Epoch: 581\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8996864 ]\n",
      " [0.86996952]\n",
      " [0.88240436]]\n",
      "Loss: \n",
      " 0.0001899090793831336\n",
      "\n",
      "\n",
      "Epoch: 582\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8997082 ]\n",
      " [0.86999376]\n",
      " [0.88242862]]\n",
      "Loss: \n",
      " 0.00018965276045248888\n",
      "\n",
      "\n",
      "Epoch: 583\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89972989]\n",
      " [0.87001789]\n",
      " [0.88245277]]\n",
      "Loss: \n",
      " 0.00018939873410384747\n",
      "\n",
      "\n",
      "Epoch: 584\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89975148]\n",
      " [0.87004191]\n",
      " [0.8824768 ]]\n",
      "Loss: \n",
      " 0.00018914697841186903\n",
      "\n",
      "\n",
      "Epoch: 585\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89977297]\n",
      " [0.87006581]\n",
      " [0.88250072]]\n",
      "Loss: \n",
      " 0.00018889747167566897\n",
      "\n",
      "\n",
      "Epoch: 586\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89979436]\n",
      " [0.8700896 ]\n",
      " [0.88252452]]\n",
      "Loss: \n",
      " 0.0001886501924163265\n",
      "\n",
      "\n",
      "Epoch: 587\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89981565]\n",
      " [0.87011327]\n",
      " [0.88254822]]\n",
      "Loss: \n",
      " 0.0001884051193744284\n",
      "\n",
      "\n",
      "Epoch: 588\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89983684]\n",
      " [0.87013683]\n",
      " [0.8825718 ]]\n",
      "Loss: \n",
      " 0.00018816223150761477\n",
      "\n",
      "\n",
      "Epoch: 589\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89985792]\n",
      " [0.87016029]\n",
      " [0.88259528]]\n",
      "Loss: \n",
      " 0.0001879215079881719\n",
      "\n",
      "\n",
      "Epoch: 590\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89987891]\n",
      " [0.87018363]\n",
      " [0.88261864]]\n",
      "Loss: \n",
      " 0.00018768292820066224\n",
      "\n",
      "\n",
      "Epoch: 591\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89989981]\n",
      " [0.87020686]\n",
      " [0.8826419 ]]\n",
      "Loss: \n",
      " 0.0001874464717395672\n",
      "\n",
      "\n",
      "Epoch: 592\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8999206 ]\n",
      " [0.87022998]\n",
      " [0.88266504]]\n",
      "Loss: \n",
      " 0.00018721211840696142\n",
      "\n",
      "\n",
      "Epoch: 593\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8999413 ]\n",
      " [0.87025299]\n",
      " [0.88268808]]\n",
      "Loss: \n",
      " 0.00018697984821023763\n",
      "\n",
      "\n",
      "Epoch: 594\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89996189]\n",
      " [0.87027589]\n",
      " [0.88271101]]\n",
      "Loss: \n",
      " 0.00018674964135981576\n",
      "\n",
      "\n",
      "Epoch: 595\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8999824 ]\n",
      " [0.87029868]\n",
      " [0.88273383]]\n",
      "Loss: \n",
      " 0.00018652147826692523\n",
      "\n",
      "\n",
      "Epoch: 596\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9000028 ]\n",
      " [0.87032137]\n",
      " [0.88275655]]\n",
      "Loss: \n",
      " 0.00018629533954137988\n",
      "\n",
      "\n",
      "Epoch: 597\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90002312]\n",
      " [0.87034395]\n",
      " [0.88277916]]\n",
      "Loss: \n",
      " 0.0001860712059894046\n",
      "\n",
      "\n",
      "Epoch: 598\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90004333]\n",
      " [0.87036642]\n",
      " [0.88280167]]\n",
      "Loss: \n",
      " 0.00018584905861147318\n",
      "\n",
      "\n",
      "Epoch: 599\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90006346]\n",
      " [0.87038879]\n",
      " [0.88282407]]\n",
      "Loss: \n",
      " 0.00018562887860017253\n",
      "\n",
      "\n",
      "Epoch: 600\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90008349]\n",
      " [0.87041105]\n",
      " [0.88284637]]\n",
      "Loss: \n",
      " 0.00018541064733810014\n",
      "\n",
      "\n",
      "Epoch: 601\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90010342]\n",
      " [0.87043321]\n",
      " [0.88286856]]\n",
      "Loss: \n",
      " 0.00018519434639579002\n",
      "\n",
      "\n",
      "Epoch: 602\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90012327]\n",
      " [0.87045526]\n",
      " [0.88289065]]\n",
      "Loss: \n",
      " 0.00018497995752964278\n",
      "\n",
      "\n",
      "Epoch: 603\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90014302]\n",
      " [0.87047721]\n",
      " [0.88291264]]\n",
      "Loss: \n",
      " 0.00018476746267990235\n",
      "\n",
      "\n",
      "Epoch: 604\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90016268]\n",
      " [0.87049906]\n",
      " [0.88293453]]\n",
      "Loss: \n",
      " 0.00018455684396865562\n",
      "\n",
      "\n",
      "Epoch: 605\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90018224]\n",
      " [0.8705208 ]\n",
      " [0.88295631]]\n",
      "Loss: \n",
      " 0.00018434808369783106\n",
      "\n",
      "\n",
      "Epoch: 606\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90020172]\n",
      " [0.87054244]\n",
      " [0.882978  ]]\n",
      "Loss: \n",
      " 0.0001841411643472633\n",
      "\n",
      "\n",
      "Epoch: 607\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90022111]\n",
      " [0.87056398]\n",
      " [0.88299958]]\n",
      "Loss: \n",
      " 0.00018393606857273855\n",
      "\n",
      "\n",
      "Epoch: 608\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9002404 ]\n",
      " [0.87058542]\n",
      " [0.88302106]]\n",
      "Loss: \n",
      " 0.00018373277920408887\n",
      "\n",
      "\n",
      "Epoch: 609\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90025961]\n",
      " [0.87060676]\n",
      " [0.88304245]]\n",
      "Loss: \n",
      " 0.0001835312792433097\n",
      "\n",
      "\n",
      "Epoch: 610\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90027873]\n",
      " [0.870628  ]\n",
      " [0.88306373]]\n",
      "Loss: \n",
      " 0.00018333155186267615\n",
      "\n",
      "\n",
      "Epoch: 611\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90029776]\n",
      " [0.87064914]\n",
      " [0.88308492]]\n",
      "Loss: \n",
      " 0.00018313358040291226\n",
      "\n",
      "\n",
      "Epoch: 612\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9003167 ]\n",
      " [0.87067018]\n",
      " [0.88310601]]\n",
      "Loss: \n",
      " 0.0001829373483713627\n",
      "\n",
      "\n",
      "Epoch: 613\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90033556]\n",
      " [0.87069112]\n",
      " [0.883127  ]]\n",
      "Loss: \n",
      " 0.0001827428394401878\n",
      "\n",
      "\n",
      "Epoch: 614\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90035432]\n",
      " [0.87071196]\n",
      " [0.8831479 ]]\n",
      "Loss: \n",
      " 0.00018255003744459147\n",
      "\n",
      "\n",
      "Epoch: 615\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.900373  ]\n",
      " [0.87073271]\n",
      " [0.88316869]]\n",
      "Loss: \n",
      " 0.00018235892638105518\n",
      "\n",
      "\n",
      "Epoch: 616\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9003916 ]\n",
      " [0.87075336]\n",
      " [0.8831894 ]]\n",
      "Loss: \n",
      " 0.0001821694904056006\n",
      "\n",
      "\n",
      "Epoch: 617\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90041011]\n",
      " [0.87077391]\n",
      " [0.88321001]]\n",
      "Loss: \n",
      " 0.000181981713832071\n",
      "\n",
      "\n",
      "Epoch: 618\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90042853]\n",
      " [0.87079437]\n",
      " [0.88323052]]\n",
      "Loss: \n",
      " 0.0001817955811304386\n",
      "\n",
      "\n",
      "Epoch: 619\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90044687]\n",
      " [0.87081473]\n",
      " [0.88325094]]\n",
      "Loss: \n",
      " 0.0001816110769251234\n",
      "\n",
      "\n",
      "Epoch: 620\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90046512]\n",
      " [0.870835  ]\n",
      " [0.88327126]]\n",
      "Loss: \n",
      " 0.00018142818599333125\n",
      "\n",
      "\n",
      "Epoch: 621\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90048329]\n",
      " [0.87085517]\n",
      " [0.88329149]]\n",
      "Loss: \n",
      " 0.000181246893263424\n",
      "\n",
      "\n",
      "Epoch: 622\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90050138]\n",
      " [0.87087525]\n",
      " [0.88331163]]\n",
      "Loss: \n",
      " 0.0001810671838132923\n",
      "\n",
      "\n",
      "Epoch: 623\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90051938]\n",
      " [0.87089524]\n",
      " [0.88333168]]\n",
      "Loss: \n",
      " 0.00018088904286876162\n",
      "\n",
      "\n",
      "Epoch: 624\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9005373 ]\n",
      " [0.87091513]\n",
      " [0.88335163]]\n",
      "Loss: \n",
      " 0.00018071245580200223\n",
      "\n",
      "\n",
      "Epoch: 625\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90055514]\n",
      " [0.87093493]\n",
      " [0.8833715 ]]\n",
      "Loss: \n",
      " 0.0001805374081299765\n",
      "\n",
      "\n",
      "Epoch: 626\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9005729 ]\n",
      " [0.87095463]\n",
      " [0.88339127]]\n",
      "Loss: \n",
      " 0.00018036388551288094\n",
      "\n",
      "\n",
      "Epoch: 627\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90059057]\n",
      " [0.87097425]\n",
      " [0.88341095]]\n",
      "Loss: \n",
      " 0.00018019187375263539\n",
      "\n",
      "\n",
      "Epoch: 628\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90060817]\n",
      " [0.87099378]\n",
      " [0.88343054]]\n",
      "Loss: \n",
      " 0.00018002135879136396\n",
      "\n",
      "\n",
      "Epoch: 629\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90062568]\n",
      " [0.87101321]\n",
      " [0.88345004]]\n",
      "Loss: \n",
      " 0.0001798523267098973\n",
      "\n",
      "\n",
      "Epoch: 630\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90064311]\n",
      " [0.87103255]\n",
      " [0.88346946]]\n",
      "Loss: \n",
      " 0.00017968476372631553\n",
      "\n",
      "\n",
      "Epoch: 631\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90066047]\n",
      " [0.87105181]\n",
      " [0.88348878]]\n",
      "Loss: \n",
      " 0.00017951865619447865\n",
      "\n",
      "\n",
      "Epoch: 632\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90067774]\n",
      " [0.87107097]\n",
      " [0.88350802]]\n",
      "Loss: \n",
      " 0.00017935399060258462\n",
      "\n",
      "\n",
      "Epoch: 633\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90069494]\n",
      " [0.87109005]\n",
      " [0.88352716]]\n",
      "Loss: \n",
      " 0.0001791907535717517\n",
      "\n",
      "\n",
      "Epoch: 634\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90071205]\n",
      " [0.87110904]\n",
      " [0.88354622]]\n",
      "Loss: \n",
      " 0.00017902893185461294\n",
      "\n",
      "\n",
      "Epoch: 635\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90072909]\n",
      " [0.87112794]\n",
      " [0.8835652 ]]\n",
      "Loss: \n",
      " 0.0001788685123339212\n",
      "\n",
      "\n",
      "Epoch: 636\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90074605]\n",
      " [0.87114675]\n",
      " [0.88358409]]\n",
      "Loss: \n",
      " 0.0001787094820211734\n",
      "\n",
      "\n",
      "Epoch: 637\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90076294]\n",
      " [0.87116548]\n",
      " [0.88360289]]\n",
      "Loss: \n",
      " 0.00017855182805525237\n",
      "\n",
      "\n",
      "Epoch: 638\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90077974]\n",
      " [0.87118412]\n",
      " [0.8836216 ]]\n",
      "Loss: \n",
      " 0.00017839553770108754\n",
      "\n",
      "\n",
      "Epoch: 639\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90079648]\n",
      " [0.87120267]\n",
      " [0.88364023]]\n",
      "Loss: \n",
      " 0.00017824059834831686\n",
      "\n",
      "\n",
      "Epoch: 640\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90081313]\n",
      " [0.87122114]\n",
      " [0.88365878]]\n",
      "Loss: \n",
      " 0.00017808699750999042\n",
      "\n",
      "\n",
      "Epoch: 641\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90082971]\n",
      " [0.87123952]\n",
      " [0.88367724]]\n",
      "Loss: \n",
      " 0.0001779347228212568\n",
      "\n",
      "\n",
      "Epoch: 642\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90084621]\n",
      " [0.87125782]\n",
      " [0.88369562]]\n",
      "Loss: \n",
      " 0.00017778376203808608\n",
      "\n",
      "\n",
      "Epoch: 643\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90086264]\n",
      " [0.87127603]\n",
      " [0.88371391]]\n",
      "Loss: \n",
      " 0.00017763410303600405\n",
      "\n",
      "\n",
      "Epoch: 644\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90087899]\n",
      " [0.87129416]\n",
      " [0.88373213]]\n",
      "Loss: \n",
      " 0.00017748573380883595\n",
      "\n",
      "\n",
      "Epoch: 645\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90089527]\n",
      " [0.8713122 ]\n",
      " [0.88375026]]\n",
      "Loss: \n",
      " 0.00017733864246747029\n",
      "\n",
      "\n",
      "Epoch: 646\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90091148]\n",
      " [0.87133016]\n",
      " [0.8837683 ]]\n",
      "Loss: \n",
      " 0.0001771928172386325\n",
      "\n",
      "\n",
      "Epoch: 647\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90092761]\n",
      " [0.87134804]\n",
      " [0.88378627]]\n",
      "Loss: \n",
      " 0.00017704824646366267\n",
      "\n",
      "\n",
      "Epoch: 648\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90094367]\n",
      " [0.87136584]\n",
      " [0.88380415]]\n",
      "Loss: \n",
      " 0.00017690491859733714\n",
      "\n",
      "\n",
      "Epoch: 649\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90095965]\n",
      " [0.87138356]\n",
      " [0.88382195]]\n",
      "Loss: \n",
      " 0.00017676282220666943\n",
      "\n",
      "\n",
      "Epoch: 650\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90097556]\n",
      " [0.87140119]\n",
      " [0.88383968]]\n",
      "Loss: \n",
      " 0.000176621945969754\n",
      "\n",
      "\n",
      "Epoch: 651\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90099141]\n",
      " [0.87141874]\n",
      " [0.88385732]]\n",
      "Loss: \n",
      " 0.00017648227867459145\n",
      "\n",
      "\n",
      "Epoch: 652\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90100718]\n",
      " [0.87143621]\n",
      " [0.88387488]]\n",
      "Loss: \n",
      " 0.00017634380921795686\n",
      "\n",
      "\n",
      "Epoch: 653\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90102287]\n",
      " [0.8714536 ]\n",
      " [0.88389237]]\n",
      "Loss: \n",
      " 0.00017620652660426607\n",
      "\n",
      "\n",
      "Epoch: 654\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9010385 ]\n",
      " [0.87147092]\n",
      " [0.88390977]]\n",
      "Loss: \n",
      " 0.00017607041994446046\n",
      "\n",
      "\n",
      "Epoch: 655\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90105406]\n",
      " [0.87148815]\n",
      " [0.8839271 ]]\n",
      "Loss: \n",
      " 0.00017593547845488772\n",
      "\n",
      "\n",
      "Epoch: 656\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90106954]\n",
      " [0.8715053 ]\n",
      " [0.88394434]]\n",
      "Loss: \n",
      " 0.00017580169145622505\n",
      "\n",
      "\n",
      "Epoch: 657\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90108496]\n",
      " [0.87152238]\n",
      " [0.88396151]]\n",
      "Loss: \n",
      " 0.00017566904837239597\n",
      "\n",
      "\n",
      "Epoch: 658\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90110031]\n",
      " [0.87153937]\n",
      " [0.88397861]]\n",
      "Loss: \n",
      " 0.00017553753872948468\n",
      "\n",
      "\n",
      "Epoch: 659\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90111559]\n",
      " [0.87155629]\n",
      " [0.88399562]]\n",
      "Loss: \n",
      " 0.00017540715215470508\n",
      "\n",
      "\n",
      "Epoch: 660\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9011308 ]\n",
      " [0.87157313]\n",
      " [0.88401256]]\n",
      "Loss: \n",
      " 0.0001752778783753287\n",
      "\n",
      "\n",
      "Epoch: 661\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90114594]\n",
      " [0.87158989]\n",
      " [0.88402942]]\n",
      "Loss: \n",
      " 0.00017514970721767848\n",
      "\n",
      "\n",
      "Epoch: 662\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90116101]\n",
      " [0.87160658]\n",
      " [0.88404621]]\n",
      "Loss: \n",
      " 0.00017502262860608834\n",
      "\n",
      "\n",
      "Epoch: 663\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90117601]\n",
      " [0.87162319]\n",
      " [0.88406292]]\n",
      "Loss: \n",
      " 0.000174896632561895\n",
      "\n",
      "\n",
      "Epoch: 664\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90119095]\n",
      " [0.87163972]\n",
      " [0.88407956]]\n",
      "Loss: \n",
      " 0.00017477170920244506\n",
      "\n",
      "\n",
      "Epoch: 665\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90120582]\n",
      " [0.87165618]\n",
      " [0.88409612]]\n",
      "Loss: \n",
      " 0.0001746478487401081\n",
      "\n",
      "\n",
      "Epoch: 666\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90122062]\n",
      " [0.87167257]\n",
      " [0.88411261]]\n",
      "Loss: \n",
      " 0.0001745250414812955\n",
      "\n",
      "\n",
      "Epoch: 667\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90123536]\n",
      " [0.87168887]\n",
      " [0.88412902]]\n",
      "Loss: \n",
      " 0.0001744032778254942\n",
      "\n",
      "\n",
      "Epoch: 668\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90125003]\n",
      " [0.87170511]\n",
      " [0.88414536]]\n",
      "Loss: \n",
      " 0.00017428254826431036\n",
      "\n",
      "\n",
      "Epoch: 669\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90126464]\n",
      " [0.87172127]\n",
      " [0.88416163]]\n",
      "Loss: \n",
      " 0.00017416284338053113\n",
      "\n",
      "\n",
      "Epoch: 670\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90127918]\n",
      " [0.87173735]\n",
      " [0.88417783]]\n",
      "Loss: \n",
      " 0.00017404415384719146\n",
      "\n",
      "\n",
      "Epoch: 671\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90129365]\n",
      " [0.87175337]\n",
      " [0.88419395]]\n",
      "Loss: \n",
      " 0.00017392647042664084\n",
      "\n",
      "\n",
      "Epoch: 672\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90130806]\n",
      " [0.87176931]\n",
      " [0.88421   ]]\n",
      "Loss: \n",
      " 0.00017380978396963173\n",
      "\n",
      "\n",
      "Epoch: 673\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9013224 ]\n",
      " [0.87178517]\n",
      " [0.88422597]]\n",
      "Loss: \n",
      " 0.00017369408541442855\n",
      "\n",
      "\n",
      "Epoch: 674\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90133668]\n",
      " [0.87180097]\n",
      " [0.88424188]]\n",
      "Loss: \n",
      " 0.00017357936578590006\n",
      "\n",
      "\n",
      "Epoch: 675\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9013509 ]\n",
      " [0.87181669]\n",
      " [0.88425772]]\n",
      "Loss: \n",
      " 0.00017346561619464233\n",
      "\n",
      "\n",
      "Epoch: 676\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90136506]\n",
      " [0.87183234]\n",
      " [0.88427348]]\n",
      "Loss: \n",
      " 0.00017335282783610716\n",
      "\n",
      "\n",
      "Epoch: 677\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90137915]\n",
      " [0.87184792]\n",
      " [0.88428917]]\n",
      "Loss: \n",
      " 0.0001732409919897314\n",
      "\n",
      "\n",
      "Epoch: 678\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90139317]\n",
      " [0.87186343]\n",
      " [0.8843048 ]]\n",
      "Loss: \n",
      " 0.0001731301000180919\n",
      "\n",
      "\n",
      "Epoch: 679\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90140714]\n",
      " [0.87187887]\n",
      " [0.88432035]]\n",
      "Loss: \n",
      " 0.00017302014336604646\n",
      "\n",
      "\n",
      "Epoch: 680\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90142104]\n",
      " [0.87189423]\n",
      " [0.88433584]]\n",
      "Loss: \n",
      " 0.0001729111135599111\n",
      "\n",
      "\n",
      "Epoch: 681\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90143488]\n",
      " [0.87190953]\n",
      " [0.88435125]]\n",
      "Loss: \n",
      " 0.00017280300220663076\n",
      "\n",
      "\n",
      "Epoch: 682\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90144866]\n",
      " [0.87192476]\n",
      " [0.8843666 ]]\n",
      "Loss: \n",
      " 0.00017269580099295493\n",
      "\n",
      "\n",
      "Epoch: 683\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90146237]\n",
      " [0.87193992]\n",
      " [0.88438188]]\n",
      "Loss: \n",
      " 0.00017258950168463506\n",
      "\n",
      "\n",
      "Epoch: 684\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90147603]\n",
      " [0.87195501]\n",
      " [0.88439709]]\n",
      "Loss: \n",
      " 0.00017248409612562846\n",
      "\n",
      "\n",
      "Epoch: 685\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90148963]\n",
      " [0.87197003]\n",
      " [0.88441224]]\n",
      "Loss: \n",
      " 0.0001723795762372933\n",
      "\n",
      "\n",
      "Epoch: 686\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90150316]\n",
      " [0.87198499]\n",
      " [0.88442731]]\n",
      "Loss: \n",
      " 0.00017227593401762081\n",
      "\n",
      "\n",
      "Epoch: 687\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90151664]\n",
      " [0.87199987]\n",
      " [0.88444232]]\n",
      "Loss: \n",
      " 0.00017217316154045416\n",
      "\n",
      "\n",
      "Epoch: 688\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90153005]\n",
      " [0.87201469]\n",
      " [0.88445726]]\n",
      "Loss: \n",
      " 0.00017207125095472593\n",
      "\n",
      "\n",
      "Epoch: 689\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9015434 ]\n",
      " [0.87202944]\n",
      " [0.88447214]]\n",
      "Loss: \n",
      " 0.0001719701944836975\n",
      "\n",
      "\n",
      "Epoch: 690\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9015567 ]\n",
      " [0.87204412]\n",
      " [0.88448695]]\n",
      "Loss: \n",
      " 0.00017186998442421535\n",
      "\n",
      "\n",
      "Epoch: 691\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90156994]\n",
      " [0.87205874]\n",
      " [0.88450169]]\n",
      "Loss: \n",
      " 0.0001717706131459665\n",
      "\n",
      "\n",
      "Epoch: 692\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90158311]\n",
      " [0.87207329]\n",
      " [0.88451637]]\n",
      "Loss: \n",
      " 0.00017167207309074073\n",
      "\n",
      "\n",
      "Epoch: 693\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90159623]\n",
      " [0.87208778]\n",
      " [0.88453099]]\n",
      "Loss: \n",
      " 0.00017157435677172392\n",
      "\n",
      "\n",
      "Epoch: 694\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9016093 ]\n",
      " [0.8721022 ]\n",
      " [0.88454554]]\n",
      "Loss: \n",
      " 0.00017147745677275627\n",
      "\n",
      "\n",
      "Epoch: 695\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9016223 ]\n",
      " [0.87211655]\n",
      " [0.88456002]]\n",
      "Loss: \n",
      " 0.0001713813657476475\n",
      "\n",
      "\n",
      "Epoch: 696\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90163524]\n",
      " [0.87213084]\n",
      " [0.88457444]]\n",
      "Loss: \n",
      " 0.00017128607641945904\n",
      "\n",
      "\n",
      "Epoch: 697\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90164813]\n",
      " [0.87214507]\n",
      " [0.8845888 ]]\n",
      "Loss: \n",
      " 0.00017119158157981147\n",
      "\n",
      "\n",
      "Epoch: 698\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90166096]\n",
      " [0.87215923]\n",
      " [0.88460309]]\n",
      "Loss: \n",
      " 0.00017109787408820993\n",
      "\n",
      "\n",
      "Epoch: 699\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90167374]\n",
      " [0.87217332]\n",
      " [0.88461732]]\n",
      "Loss: \n",
      " 0.00017100494687134974\n",
      "\n",
      "\n",
      "Epoch: 700\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90168646]\n",
      " [0.87218735]\n",
      " [0.88463149]]\n",
      "Loss: \n",
      " 0.0001709127929224592\n",
      "\n",
      "\n",
      "Epoch: 701\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90169912]\n",
      " [0.87220132]\n",
      " [0.88464559]]\n",
      "Loss: \n",
      " 0.00017082140530062185\n",
      "\n",
      "\n",
      "Epoch: 702\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90171173]\n",
      " [0.87221523]\n",
      " [0.88465963]]\n",
      "Loss: \n",
      " 0.00017073077713013044\n",
      "\n",
      "\n",
      "Epoch: 703\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90172428]\n",
      " [0.87222907]\n",
      " [0.88467361]]\n",
      "Loss: \n",
      " 0.00017064090159982803\n",
      "\n",
      "\n",
      "Epoch: 704\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90173677]\n",
      " [0.87224285]\n",
      " [0.88468753]]\n",
      "Loss: \n",
      " 0.00017055177196247267\n",
      "\n",
      "\n",
      "Epoch: 705\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90174921]\n",
      " [0.87225657]\n",
      " [0.88470139]]\n",
      "Loss: \n",
      " 0.00017046338153409277\n",
      "\n",
      "\n",
      "Epoch: 706\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90176159]\n",
      " [0.87227023]\n",
      " [0.88471519]]\n",
      "Loss: \n",
      " 0.00017037572369336235\n",
      "\n",
      "\n",
      "Epoch: 707\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90177393]\n",
      " [0.87228382]\n",
      " [0.88472892]]\n",
      "Loss: \n",
      " 0.00017028879188098447\n",
      "\n",
      "\n",
      "Epoch: 708\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9017862 ]\n",
      " [0.87229736]\n",
      " [0.8847426 ]]\n",
      "Loss: \n",
      " 0.00017020257959906226\n",
      "\n",
      "\n",
      "Epoch: 709\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90179842]\n",
      " [0.87231083]\n",
      " [0.88475621]]\n",
      "Loss: \n",
      " 0.00017011708041048956\n",
      "\n",
      "\n",
      "Epoch: 710\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90181059]\n",
      " [0.87232424]\n",
      " [0.88476977]]\n",
      "Loss: \n",
      " 0.00017003228793837193\n",
      "\n",
      "\n",
      "Epoch: 711\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90182271]\n",
      " [0.87233759]\n",
      " [0.88478326]]\n",
      "Loss: \n",
      " 0.00016994819586539024\n",
      "\n",
      "\n",
      "Epoch: 712\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90183477]\n",
      " [0.87235088]\n",
      " [0.8847967 ]]\n",
      "Loss: \n",
      " 0.0001698647979332496\n",
      "\n",
      "\n",
      "Epoch: 713\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90184677]\n",
      " [0.87236412]\n",
      " [0.88481007]]\n",
      "Loss: \n",
      " 0.00016978208794207078\n",
      "\n",
      "\n",
      "Epoch: 714\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90185873]\n",
      " [0.87237729]\n",
      " [0.88482339]]\n",
      "Loss: \n",
      " 0.00016970005974982155\n",
      "\n",
      "\n",
      "Epoch: 715\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90187063]\n",
      " [0.8723904 ]\n",
      " [0.88483665]]\n",
      "Loss: \n",
      " 0.0001696187072717391\n",
      "\n",
      "\n",
      "Epoch: 716\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90188248]\n",
      " [0.87240345]\n",
      " [0.88484985]]\n",
      "Loss: \n",
      " 0.00016953802447977522\n",
      "\n",
      "\n",
      "Epoch: 717\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90189428]\n",
      " [0.87241645]\n",
      " [0.884863  ]]\n",
      "Loss: \n",
      " 0.00016945800540202157\n",
      "\n",
      "\n",
      "Epoch: 718\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90190603]\n",
      " [0.87242938]\n",
      " [0.88487608]]\n",
      "Loss: \n",
      " 0.0001693786441221757\n",
      "\n",
      "\n",
      "Epoch: 719\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90191772]\n",
      " [0.87244226]\n",
      " [0.88488911]]\n",
      "Loss: \n",
      " 0.0001692999347789737\n",
      "\n",
      "\n",
      "Epoch: 720\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90192937]\n",
      " [0.87245508]\n",
      " [0.88490208]]\n",
      "Loss: \n",
      " 0.00016922187156565873\n",
      "\n",
      "\n",
      "Epoch: 721\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90194096]\n",
      " [0.87246785]\n",
      " [0.88491499]]\n",
      "Loss: \n",
      " 0.00016914444872944431\n",
      "\n",
      "\n",
      "Epoch: 722\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9019525 ]\n",
      " [0.87248055]\n",
      " [0.88492785]]\n",
      "Loss: \n",
      " 0.00016906766057098426\n",
      "\n",
      "\n",
      "Epoch: 723\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90196399]\n",
      " [0.8724932 ]\n",
      " [0.88494065]]\n",
      "Loss: \n",
      " 0.00016899150144383888\n",
      "\n",
      "\n",
      "Epoch: 724\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90197544]\n",
      " [0.87250579]\n",
      " [0.8849534 ]]\n",
      "Loss: \n",
      " 0.00016891596575397026\n",
      "\n",
      "\n",
      "Epoch: 725\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90198683]\n",
      " [0.87251833]\n",
      " [0.88496609]]\n",
      "Loss: \n",
      " 0.0001688410479592145\n",
      "\n",
      "\n",
      "Epoch: 726\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90199817]\n",
      " [0.8725308 ]\n",
      " [0.88497872]]\n",
      "Loss: \n",
      " 0.000168766742568781\n",
      "\n",
      "\n",
      "Epoch: 727\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90200946]\n",
      " [0.87254323]\n",
      " [0.8849913 ]]\n",
      "Loss: \n",
      " 0.000168693044142748\n",
      "\n",
      "\n",
      "Epoch: 728\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9020207 ]\n",
      " [0.87255559]\n",
      " [0.88500383]]\n",
      "Loss: \n",
      " 0.00016861994729156255\n",
      "\n",
      "\n",
      "Epoch: 729\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9020319 ]\n",
      " [0.8725679 ]\n",
      " [0.88501629]]\n",
      "Loss: \n",
      " 0.00016854744667555192\n",
      "\n",
      "\n",
      "Epoch: 730\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90204304]\n",
      " [0.87258016]\n",
      " [0.88502871]]\n",
      "Loss: \n",
      " 0.00016847553700442746\n",
      "\n",
      "\n",
      "Epoch: 731\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90205414]\n",
      " [0.87259236]\n",
      " [0.88504107]]\n",
      "Loss: \n",
      " 0.00016840421303681742\n",
      "\n",
      "\n",
      "Epoch: 732\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90206518]\n",
      " [0.87260451]\n",
      " [0.88505338]]\n",
      "Loss: \n",
      " 0.00016833346957976863\n",
      "\n",
      "\n",
      "Epoch: 733\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90207618]\n",
      " [0.8726166 ]\n",
      " [0.88506563]]\n",
      "Loss: \n",
      " 0.00016826330148829297\n",
      "\n",
      "\n",
      "Epoch: 734\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90208713]\n",
      " [0.87262864]\n",
      " [0.88507783]]\n",
      "Loss: \n",
      " 0.00016819370366488802\n",
      "\n",
      "\n",
      "Epoch: 735\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90209804]\n",
      " [0.87264062]\n",
      " [0.88508998]]\n",
      "Loss: \n",
      " 0.00016812467105908492\n",
      "\n",
      "\n",
      "Epoch: 736\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90210889]\n",
      " [0.87265255]\n",
      " [0.88510207]]\n",
      "Loss: \n",
      " 0.00016805619866697713\n",
      "\n",
      "\n",
      "Epoch: 737\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9021197 ]\n",
      " [0.87266443]\n",
      " [0.88511411]]\n",
      "Loss: \n",
      " 0.00016798828153078067\n",
      "\n",
      "\n",
      "Epoch: 738\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90213046]\n",
      " [0.87267625]\n",
      " [0.8851261 ]]\n",
      "Loss: \n",
      " 0.00016792091473837433\n",
      "\n",
      "\n",
      "Epoch: 739\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90214118]\n",
      " [0.87268802]\n",
      " [0.88513803]]\n",
      "Loss: \n",
      " 0.00016785409342286747\n",
      "\n",
      "\n",
      "Epoch: 740\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90215184]\n",
      " [0.87269974]\n",
      " [0.88514992]]\n",
      "Loss: \n",
      " 0.0001677878127621492\n",
      "\n",
      "\n",
      "Epoch: 741\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90216247]\n",
      " [0.87271141]\n",
      " [0.88516175]]\n",
      "Loss: \n",
      " 0.0001677220679784601\n",
      "\n",
      "\n",
      "Epoch: 742\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90217304]\n",
      " [0.87272302]\n",
      " [0.88517353]]\n",
      "Loss: \n",
      " 0.00016765685433796937\n",
      "\n",
      "\n",
      "Epoch: 743\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90218357]\n",
      " [0.87273458]\n",
      " [0.88518526]]\n",
      "Loss: \n",
      " 0.0001675921671503363\n",
      "\n",
      "\n",
      "Epoch: 744\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90219405]\n",
      " [0.87274609]\n",
      " [0.88519694]]\n",
      "Loss: \n",
      " 0.0001675280017682888\n",
      "\n",
      "\n",
      "Epoch: 745\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90220449]\n",
      " [0.87275755]\n",
      " [0.88520857]]\n",
      "Loss: \n",
      " 0.00016746435358722548\n",
      "\n",
      "\n",
      "Epoch: 746\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90221489]\n",
      " [0.87276896]\n",
      " [0.88522015]]\n",
      "Loss: \n",
      " 0.00016740121804477732\n",
      "\n",
      "\n",
      "Epoch: 747\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90222523]\n",
      " [0.87278032]\n",
      " [0.88523167]]\n",
      "Loss: \n",
      " 0.0001673385906204207\n",
      "\n",
      "\n",
      "Epoch: 748\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90223554]\n",
      " [0.87279162]\n",
      " [0.88524315]]\n",
      "Loss: \n",
      " 0.0001672764668350645\n",
      "\n",
      "\n",
      "Epoch: 749\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90224579]\n",
      " [0.87280288]\n",
      " [0.88525458]]\n",
      "Loss: \n",
      " 0.00016721484225064523\n",
      "\n",
      "\n",
      "Epoch: 750\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90225601]\n",
      " [0.87281408]\n",
      " [0.88526596]]\n",
      "Loss: \n",
      " 0.0001671537124697431\n",
      "\n",
      "\n",
      "Epoch: 751\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90226618]\n",
      " [0.87282524]\n",
      " [0.88527729]]\n",
      "Loss: \n",
      " 0.00016709307313517887\n",
      "\n",
      "\n",
      "Epoch: 752\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9022763 ]\n",
      " [0.87283634]\n",
      " [0.88528856]]\n",
      "Loss: \n",
      " 0.00016703291992963739\n",
      "\n",
      "\n",
      "Epoch: 753\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90228638]\n",
      " [0.8728474 ]\n",
      " [0.8852998 ]]\n",
      "Loss: \n",
      " 0.00016697324857527232\n",
      "\n",
      "\n",
      "Epoch: 754\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90229642]\n",
      " [0.87285841]\n",
      " [0.88531098]]\n",
      "Loss: \n",
      " 0.000166914054833335\n",
      "\n",
      "\n",
      "Epoch: 755\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90230642]\n",
      " [0.87286936]\n",
      " [0.88532211]]\n",
      "Loss: \n",
      " 0.0001668553345038014\n",
      "\n",
      "\n",
      "Epoch: 756\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90231637]\n",
      " [0.87288027]\n",
      " [0.8853332 ]]\n",
      "Loss: \n",
      " 0.0001667970834249814\n",
      "\n",
      "\n",
      "Epoch: 757\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90232628]\n",
      " [0.87289113]\n",
      " [0.88534424]]\n",
      "Loss: \n",
      " 0.00016673929747317517\n",
      "\n",
      "\n",
      "Epoch: 758\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90233614]\n",
      " [0.87290194]\n",
      " [0.88535523]]\n",
      "Loss: \n",
      " 0.00016668197256229728\n",
      "\n",
      "\n",
      "Epoch: 759\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90234597]\n",
      " [0.87291271]\n",
      " [0.88536617]]\n",
      "Loss: \n",
      " 0.00016662510464351033\n",
      "\n",
      "\n",
      "Epoch: 760\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90235575]\n",
      " [0.87292342]\n",
      " [0.88537706]]\n",
      "Loss: \n",
      " 0.0001665686897048764\n",
      "\n",
      "\n",
      "Epoch: 761\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90236548]\n",
      " [0.87293409]\n",
      " [0.88538791]]\n",
      "Loss: \n",
      " 0.00016651272377100464\n",
      "\n",
      "\n",
      "Epoch: 762\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90237518]\n",
      " [0.87294471]\n",
      " [0.88539871]]\n",
      "Loss: \n",
      " 0.00016645720290269395\n",
      "\n",
      "\n",
      "Epoch: 763\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90238483]\n",
      " [0.87295528]\n",
      " [0.88540947]]\n",
      "Loss: \n",
      " 0.0001664021231965974\n",
      "\n",
      "\n",
      "Epoch: 764\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90239445]\n",
      " [0.87296581]\n",
      " [0.88542018]]\n",
      "Loss: \n",
      " 0.00016634748078486264\n",
      "\n",
      "\n",
      "Epoch: 765\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90240402]\n",
      " [0.87297629]\n",
      " [0.88543084]]\n",
      "Loss: \n",
      " 0.00016629327183481535\n",
      "\n",
      "\n",
      "Epoch: 766\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90241355]\n",
      " [0.87298672]\n",
      " [0.88544145]]\n",
      "Loss: \n",
      " 0.00016623949254860386\n",
      "\n",
      "\n",
      "Epoch: 767\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90242304]\n",
      " [0.8729971 ]\n",
      " [0.88545202]]\n",
      "Loss: \n",
      " 0.00016618613916288022\n",
      "\n",
      "\n",
      "Epoch: 768\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90243249]\n",
      " [0.87300744]\n",
      " [0.88546255]]\n",
      "Loss: \n",
      " 0.00016613320794846154\n",
      "\n",
      "\n",
      "Epoch: 769\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90244189]\n",
      " [0.87301774]\n",
      " [0.88547303]]\n",
      "Loss: \n",
      " 0.0001660806952100101\n",
      "\n",
      "\n",
      "Epoch: 770\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90245126]\n",
      " [0.87302799]\n",
      " [0.88548346]]\n",
      "Loss: \n",
      " 0.00016602859728571254\n",
      "\n",
      "\n",
      "Epoch: 771\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90246059]\n",
      " [0.87303819]\n",
      " [0.88549385]]\n",
      "Loss: \n",
      " 0.00016597691054695272\n",
      "\n",
      "\n",
      "Epoch: 772\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90246987]\n",
      " [0.87304835]\n",
      " [0.8855042 ]]\n",
      "Loss: \n",
      " 0.00016592563139800285\n",
      "\n",
      "\n",
      "Epoch: 773\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90247912]\n",
      " [0.87305846]\n",
      " [0.8855145 ]]\n",
      "Loss: \n",
      " 0.00016587475627571826\n",
      "\n",
      "\n",
      "Epoch: 774\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90248833]\n",
      " [0.87306852]\n",
      " [0.88552475]]\n",
      "Loss: \n",
      " 0.00016582428164920427\n",
      "\n",
      "\n",
      "Epoch: 775\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90249749]\n",
      " [0.87307855]\n",
      " [0.88553497]]\n",
      "Loss: \n",
      " 0.00016577420401953566\n",
      "\n",
      "\n",
      "Epoch: 776\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90250662]\n",
      " [0.87308852]\n",
      " [0.88554513]]\n",
      "Loss: \n",
      " 0.0001657245199194386\n",
      "\n",
      "\n",
      "Epoch: 777\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90251571]\n",
      " [0.87309846]\n",
      " [0.88555526]]\n",
      "Loss: \n",
      " 0.00016567522591299353\n",
      "\n",
      "\n",
      "Epoch: 778\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90252476]\n",
      " [0.87310835]\n",
      " [0.88556534]]\n",
      "Loss: \n",
      " 0.00016562631859533904\n",
      "\n",
      "\n",
      "Epoch: 779\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90253377]\n",
      " [0.87311819]\n",
      " [0.88557538]]\n",
      "Loss: \n",
      " 0.00016557779459237983\n",
      "\n",
      "\n",
      "Epoch: 780\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90254274]\n",
      " [0.87312799]\n",
      " [0.88558537]]\n",
      "Loss: \n",
      " 0.00016552965056049348\n",
      "\n",
      "\n",
      "Epoch: 781\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90255168]\n",
      " [0.87313775]\n",
      " [0.88559532]]\n",
      "Loss: \n",
      " 0.00016548188318623854\n",
      "\n",
      "\n",
      "Epoch: 782\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90256057]\n",
      " [0.87314747]\n",
      " [0.88560523]]\n",
      "Loss: \n",
      " 0.00016543448918607725\n",
      "\n",
      "\n",
      "Epoch: 783\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90256943]\n",
      " [0.87315714]\n",
      " [0.8856151 ]]\n",
      "Loss: \n",
      " 0.00016538746530607928\n",
      "\n",
      "\n",
      "Epoch: 784\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90257825]\n",
      " [0.87316677]\n",
      " [0.88562492]]\n",
      "Loss: \n",
      " 0.00016534080832166767\n",
      "\n",
      "\n",
      "Epoch: 785\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90258703]\n",
      " [0.87317635]\n",
      " [0.88563471]]\n",
      "Loss: \n",
      " 0.0001652945150373074\n",
      "\n",
      "\n",
      "Epoch: 786\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90259578]\n",
      " [0.8731859 ]\n",
      " [0.88564445]]\n",
      "Loss: \n",
      " 0.00016524858228626166\n",
      "\n",
      "\n",
      "Epoch: 787\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90260448]\n",
      " [0.8731954 ]\n",
      " [0.88565414]]\n",
      "Loss: \n",
      " 0.00016520300693030157\n",
      "\n",
      "\n",
      "Epoch: 788\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90261315]\n",
      " [0.87320486]\n",
      " [0.8856638 ]]\n",
      "Loss: \n",
      " 0.0001651577858594489\n",
      "\n",
      "\n",
      "Epoch: 789\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90262178]\n",
      " [0.87321427]\n",
      " [0.88567342]]\n",
      "Loss: \n",
      " 0.00016511291599169704\n",
      "\n",
      "\n",
      "Epoch: 790\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90263038]\n",
      " [0.87322365]\n",
      " [0.88568299]]\n",
      "Loss: \n",
      " 0.00016506839427277162\n",
      "\n",
      "\n",
      "Epoch: 791\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90263894]\n",
      " [0.87323298]\n",
      " [0.88569253]]\n",
      "Loss: \n",
      " 0.00016502421767583932\n",
      "\n",
      "\n",
      "Epoch: 792\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90264746]\n",
      " [0.87324228]\n",
      " [0.88570202]]\n",
      "Loss: \n",
      " 0.0001649803832012732\n",
      "\n",
      "\n",
      "Epoch: 793\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90265595]\n",
      " [0.87325153]\n",
      " [0.88571147]]\n",
      "Loss: \n",
      " 0.000164936887876385\n",
      "\n",
      "\n",
      "Epoch: 794\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9026644 ]\n",
      " [0.87326074]\n",
      " [0.88572088]]\n",
      "Loss: \n",
      " 0.00016489372875517667\n",
      "\n",
      "\n",
      "Epoch: 795\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90267281]\n",
      " [0.87326991]\n",
      " [0.88573026]]\n",
      "Loss: \n",
      " 0.0001648509029180883\n",
      "\n",
      "\n",
      "Epoch: 796\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90268119]\n",
      " [0.87327904]\n",
      " [0.88573959]]\n",
      "Loss: \n",
      " 0.00016480840747175115\n",
      "\n",
      "\n",
      "Epoch: 797\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90268953]\n",
      " [0.87328813]\n",
      " [0.88574888]]\n",
      "Loss: \n",
      " 0.00016476623954874854\n",
      "\n",
      "\n",
      "Epoch: 798\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90269783]\n",
      " [0.87329717]\n",
      " [0.88575813]]\n",
      "Loss: \n",
      " 0.00016472439630735593\n",
      "\n",
      "\n",
      "Epoch: 799\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90270611]\n",
      " [0.87330618]\n",
      " [0.88576734]]\n",
      "Loss: \n",
      " 0.00016468287493131553\n",
      "\n",
      "\n",
      "Epoch: 800\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90271434]\n",
      " [0.87331515]\n",
      " [0.88577652]]\n",
      "Loss: \n",
      " 0.00016464167262959524\n",
      "\n",
      "\n",
      "Epoch: 801\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90272254]\n",
      " [0.87332408]\n",
      " [0.88578565]]\n",
      "Loss: \n",
      " 0.0001646007866361493\n",
      "\n",
      "\n",
      "Epoch: 802\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90273071]\n",
      " [0.87333297]\n",
      " [0.88579475]]\n",
      "Loss: \n",
      " 0.00016456021420968104\n",
      "\n",
      "\n",
      "Epoch: 803\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90273884]\n",
      " [0.87334182]\n",
      " [0.8858038 ]]\n",
      "Loss: \n",
      " 0.00016451995263342493\n",
      "\n",
      "\n",
      "Epoch: 804\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90274694]\n",
      " [0.87335063]\n",
      " [0.88581282]]\n",
      "Loss: \n",
      " 0.00016447999921490375\n",
      "\n",
      "\n",
      "Epoch: 805\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.902755 ]\n",
      " [0.8733594]\n",
      " [0.8858218]]\n",
      "Loss: \n",
      " 0.0001644403512857096\n",
      "\n",
      "\n",
      "Epoch: 806\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90276302]\n",
      " [0.87336813]\n",
      " [0.88583074]]\n",
      "Loss: \n",
      " 0.0001644010062012738\n",
      "\n",
      "\n",
      "Epoch: 807\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90277102]\n",
      " [0.87337683]\n",
      " [0.88583965]]\n",
      "Loss: \n",
      " 0.00016436196134065475\n",
      "\n",
      "\n",
      "Epoch: 808\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90277898]\n",
      " [0.87338548]\n",
      " [0.88584851]]\n",
      "Loss: \n",
      " 0.0001643232141063082\n",
      "\n",
      "\n",
      "Epoch: 809\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9027869 ]\n",
      " [0.8733941 ]\n",
      " [0.88585734]]\n",
      "Loss: \n",
      " 0.00016428476192386515\n",
      "\n",
      "\n",
      "Epoch: 810\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9027948 ]\n",
      " [0.87340268]\n",
      " [0.88586613]]\n",
      "Loss: \n",
      " 0.0001642466022419352\n",
      "\n",
      "\n",
      "Epoch: 811\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90280265]\n",
      " [0.87341122]\n",
      " [0.88587488]]\n",
      "Loss: \n",
      " 0.0001642087325318726\n",
      "\n",
      "\n",
      "Epoch: 812\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90281048]\n",
      " [0.87341973]\n",
      " [0.8858836 ]]\n",
      "Loss: \n",
      " 0.00016417115028757696\n",
      "\n",
      "\n",
      "Epoch: 813\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90281827]\n",
      " [0.87342819]\n",
      " [0.88589228]]\n",
      "Loss: \n",
      " 0.0001641338530252765\n",
      "\n",
      "\n",
      "Epoch: 814\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90282603]\n",
      " [0.87343662]\n",
      " [0.88590092]]\n",
      "Loss: \n",
      " 0.00016409683828333017\n",
      "\n",
      "\n",
      "Epoch: 815\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90283376]\n",
      " [0.87344501]\n",
      " [0.88590953]]\n",
      "Loss: \n",
      " 0.00016406010362200743\n",
      "\n",
      "\n",
      "Epoch: 816\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90284145]\n",
      " [0.87345337]\n",
      " [0.88591809]]\n",
      "Loss: \n",
      " 0.00016402364662330125\n",
      "\n",
      "\n",
      "Epoch: 817\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90284911]\n",
      " [0.87346169]\n",
      " [0.88592663]]\n",
      "Loss: \n",
      " 0.0001639874648907147\n",
      "\n",
      "\n",
      "Epoch: 818\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90285674]\n",
      " [0.87346997]\n",
      " [0.88593512]]\n",
      "Loss: \n",
      " 0.00016395155604906632\n",
      "\n",
      "\n",
      "Epoch: 819\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90286433]\n",
      " [0.87347821]\n",
      " [0.88594358]]\n",
      "Loss: \n",
      " 0.00016391591774429567\n",
      "\n",
      "\n",
      "Epoch: 820\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9028719 ]\n",
      " [0.87348642]\n",
      " [0.88595201]]\n",
      "Loss: \n",
      " 0.00016388054764325958\n",
      "\n",
      "\n",
      "Epoch: 821\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90287943]\n",
      " [0.87349459]\n",
      " [0.8859604 ]]\n",
      "Loss: \n",
      " 0.00016384544343354664\n",
      "\n",
      "\n",
      "Epoch: 822\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90288693]\n",
      " [0.87350273]\n",
      " [0.88596875]]\n",
      "Loss: \n",
      " 0.00016381060282328014\n",
      "\n",
      "\n",
      "Epoch: 823\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9028944 ]\n",
      " [0.87351083]\n",
      " [0.88597707]]\n",
      "Loss: \n",
      " 0.00016377602354093236\n",
      "\n",
      "\n",
      "Epoch: 824\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90290183]\n",
      " [0.87351889]\n",
      " [0.88598535]]\n",
      "Loss: \n",
      " 0.00016374170333512868\n",
      "\n",
      "\n",
      "Epoch: 825\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90290924]\n",
      " [0.87352692]\n",
      " [0.8859936 ]]\n",
      "Loss: \n",
      " 0.00016370763997447784\n",
      "\n",
      "\n",
      "Epoch: 826\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90291661]\n",
      " [0.87353491]\n",
      " [0.88600181]]\n",
      "Loss: \n",
      " 0.0001636738312473684\n",
      "\n",
      "\n",
      "Epoch: 827\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90292395]\n",
      " [0.87354287]\n",
      " [0.88600999]]\n",
      "Loss: \n",
      " 0.00016364027496179525\n",
      "\n",
      "\n",
      "Epoch: 828\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90293127]\n",
      " [0.87355079]\n",
      " [0.88601813]]\n",
      "Loss: \n",
      " 0.00016360696894518193\n",
      "\n",
      "\n",
      "Epoch: 829\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90293855]\n",
      " [0.87355868]\n",
      " [0.88602624]]\n",
      "Loss: \n",
      " 0.00016357391104419256\n",
      "\n",
      "\n",
      "Epoch: 830\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9029458 ]\n",
      " [0.87356653]\n",
      " [0.88603431]]\n",
      "Loss: \n",
      " 0.00016354109912456688\n",
      "\n",
      "\n",
      "Epoch: 831\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90295302]\n",
      " [0.87357435]\n",
      " [0.88604235]]\n",
      "Loss: \n",
      " 0.0001635085310709317\n",
      "\n",
      "\n",
      "Epoch: 832\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90296021]\n",
      " [0.87358213]\n",
      " [0.88605036]]\n",
      "Loss: \n",
      " 0.0001634762047866354\n",
      "\n",
      "\n",
      "Epoch: 833\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90296736]\n",
      " [0.87358988]\n",
      " [0.88605833]]\n",
      "Loss: \n",
      " 0.00016344411819357486\n",
      "\n",
      "\n",
      "Epoch: 834\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90297449]\n",
      " [0.8735976 ]\n",
      " [0.88606627]]\n",
      "Loss: \n",
      " 0.0001634122692320181\n",
      "\n",
      "\n",
      "Epoch: 835\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90298159]\n",
      " [0.87360528]\n",
      " [0.88607418]]\n",
      "Loss: \n",
      " 0.00016338065586044733\n",
      "\n",
      "\n",
      "Epoch: 836\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90298866]\n",
      " [0.87361293]\n",
      " [0.88608205]]\n",
      "Loss: \n",
      " 0.00016334927605537772\n",
      "\n",
      "\n",
      "Epoch: 837\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9029957 ]\n",
      " [0.87362054]\n",
      " [0.88608989]]\n",
      "Loss: \n",
      " 0.00016331812781120473\n",
      "\n",
      "\n",
      "Epoch: 838\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90300271]\n",
      " [0.87362812]\n",
      " [0.88609769]]\n",
      "Loss: \n",
      " 0.00016328720914003452\n",
      "\n",
      "\n",
      "Epoch: 839\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90300969]\n",
      " [0.87363567]\n",
      " [0.88610547]]\n",
      "Loss: \n",
      " 0.00016325651807151922\n",
      "\n",
      "\n",
      "Epoch: 840\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90301664]\n",
      " [0.87364318]\n",
      " [0.88611321]]\n",
      "Loss: \n",
      " 0.0001632260526526979\n",
      "\n",
      "\n",
      "Epoch: 841\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90302356]\n",
      " [0.87365066]\n",
      " [0.88612091]]\n",
      "Loss: \n",
      " 0.0001631958109478373\n",
      "\n",
      "\n",
      "Epoch: 842\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90303045]\n",
      " [0.87365811]\n",
      " [0.88612859]]\n",
      "Loss: \n",
      " 0.00016316579103827603\n",
      "\n",
      "\n",
      "Epoch: 843\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90303731]\n",
      " [0.87366552]\n",
      " [0.88613623]]\n",
      "Loss: \n",
      " 0.0001631359910222663\n",
      "\n",
      "\n",
      "Epoch: 844\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90304415]\n",
      " [0.8736729 ]\n",
      " [0.88614384]]\n",
      "Loss: \n",
      " 0.0001631064090148195\n",
      "\n",
      "\n",
      "Epoch: 845\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90305095]\n",
      " [0.87368025]\n",
      " [0.88615142]]\n",
      "Loss: \n",
      " 0.00016307704314755204\n",
      "\n",
      "\n",
      "Epoch: 846\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90305773]\n",
      " [0.87368757]\n",
      " [0.88615897]]\n",
      "Loss: \n",
      " 0.00016304789156853443\n",
      "\n",
      "\n",
      "Epoch: 847\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90306448]\n",
      " [0.87369485]\n",
      " [0.88616648]]\n",
      "Loss: \n",
      " 0.00016301895244213942\n",
      "\n",
      "\n",
      "Epoch: 848\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9030712 ]\n",
      " [0.87370211]\n",
      " [0.88617396]]\n",
      "Loss: \n",
      " 0.0001629902239488988\n",
      "\n",
      "\n",
      "Epoch: 849\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90307789]\n",
      " [0.87370933]\n",
      " [0.88618142]]\n",
      "Loss: \n",
      " 0.00016296170428534712\n",
      "\n",
      "\n",
      "Epoch: 850\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90308455]\n",
      " [0.87371652]\n",
      " [0.88618884]]\n",
      "Loss: \n",
      " 0.0001629333916638838\n",
      "\n",
      "\n",
      "Epoch: 851\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90309119]\n",
      " [0.87372367]\n",
      " [0.88619623]]\n",
      "Loss: \n",
      " 0.00016290528431262146\n",
      "\n",
      "\n",
      "Epoch: 852\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9030978 ]\n",
      " [0.8737308 ]\n",
      " [0.88620358]]\n",
      "Loss: \n",
      " 0.00016287738047525026\n",
      "\n",
      "\n",
      "Epoch: 853\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90310438]\n",
      " [0.87373789]\n",
      " [0.88621091]]\n",
      "Loss: \n",
      " 0.0001628496784108857\n",
      "\n",
      "\n",
      "Epoch: 854\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90311093]\n",
      " [0.87374496]\n",
      " [0.88621821]]\n",
      "Loss: \n",
      " 0.0001628221763939378\n",
      "\n",
      "\n",
      "Epoch: 855\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90311745]\n",
      " [0.87375199]\n",
      " [0.88622547]]\n",
      "Loss: \n",
      " 0.00016279487271396803\n",
      "\n",
      "\n",
      "Epoch: 856\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90312395]\n",
      " [0.87375899]\n",
      " [0.88623271]]\n",
      "Loss: \n",
      " 0.00016276776567555429\n",
      "\n",
      "\n",
      "Epoch: 857\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90313042]\n",
      " [0.87376596]\n",
      " [0.88623991]]\n",
      "Loss: \n",
      " 0.00016274085359814307\n",
      "\n",
      "\n",
      "Epoch: 858\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90313686]\n",
      " [0.8737729 ]\n",
      " [0.88624709]]\n",
      "Loss: \n",
      " 0.0001627141348159307\n",
      "\n",
      "\n",
      "Epoch: 859\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90314328]\n",
      " [0.87377981]\n",
      " [0.88625423]]\n",
      "Loss: \n",
      " 0.0001626876076777192\n",
      "\n",
      "\n",
      "Epoch: 860\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90314967]\n",
      " [0.87378668]\n",
      " [0.88626135]]\n",
      "Loss: \n",
      " 0.000162661270546785\n",
      "\n",
      "\n",
      "Epoch: 861\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90315603]\n",
      " [0.87379353]\n",
      " [0.88626843]]\n",
      "Loss: \n",
      " 0.00016263512180074996\n",
      "\n",
      "\n",
      "Epoch: 862\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90316237]\n",
      " [0.87380035]\n",
      " [0.88627549]]\n",
      "Loss: \n",
      " 0.00016260915983144203\n",
      "\n",
      "\n",
      "Epoch: 863\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90316868]\n",
      " [0.87380714]\n",
      " [0.88628251]]\n",
      "Loss: \n",
      " 0.00016258338304478724\n",
      "\n",
      "\n",
      "Epoch: 864\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90317496]\n",
      " [0.8738139 ]\n",
      " [0.88628951]]\n",
      "Loss: \n",
      " 0.0001625577898606591\n",
      "\n",
      "\n",
      "Epoch: 865\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90318122]\n",
      " [0.87382062]\n",
      " [0.88629648]]\n",
      "Loss: \n",
      " 0.00016253237871276287\n",
      "\n",
      "\n",
      "Epoch: 866\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90318745]\n",
      " [0.87382732]\n",
      " [0.88630341]]\n",
      "Loss: \n",
      " 0.0001625071480485065\n",
      "\n",
      "\n",
      "Epoch: 867\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90319366]\n",
      " [0.87383399]\n",
      " [0.88631032]]\n",
      "Loss: \n",
      " 0.00016248209632888563\n",
      "\n",
      "\n",
      "Epoch: 868\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90319983]\n",
      " [0.87384063]\n",
      " [0.8863172 ]]\n",
      "Loss: \n",
      " 0.00016245722202834741\n",
      "\n",
      "\n",
      "Epoch: 869\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90320599]\n",
      " [0.87384724]\n",
      " [0.88632405]]\n",
      "Loss: \n",
      " 0.0001624325236346834\n",
      "\n",
      "\n",
      "Epoch: 870\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90321211]\n",
      " [0.87385382]\n",
      " [0.88633088]]\n",
      "Loss: \n",
      " 0.0001624079996488892\n",
      "\n",
      "\n",
      "Epoch: 871\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90321822]\n",
      " [0.87386038]\n",
      " [0.88633767]]\n",
      "Loss: \n",
      " 0.000162383648585067\n",
      "\n",
      "\n",
      "Epoch: 872\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90322429]\n",
      " [0.8738669 ]\n",
      " [0.88634444]]\n",
      "Loss: \n",
      " 0.00016235946897029104\n",
      "\n",
      "\n",
      "Epoch: 873\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90323034]\n",
      " [0.8738734 ]\n",
      " [0.88635117]]\n",
      "Loss: \n",
      " 0.00016233545934449668\n",
      "\n",
      "\n",
      "Epoch: 874\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90323637]\n",
      " [0.87387986]\n",
      " [0.88635788]]\n",
      "Loss: \n",
      " 0.0001623116182603649\n",
      "\n",
      "\n",
      "Epoch: 875\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90324237]\n",
      " [0.8738863 ]\n",
      " [0.88636456]]\n",
      "Loss: \n",
      " 0.0001622879442832078\n",
      "\n",
      "\n",
      "Epoch: 876\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90324835]\n",
      " [0.87389271]\n",
      " [0.88637122]]\n",
      "Loss: \n",
      " 0.0001622644359908482\n",
      "\n",
      "\n",
      "Epoch: 877\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9032543 ]\n",
      " [0.87389909]\n",
      " [0.88637784]]\n",
      "Loss: \n",
      " 0.0001622410919735172\n",
      "\n",
      "\n",
      "Epoch: 878\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90326022]\n",
      " [0.87390544]\n",
      " [0.88638444]]\n",
      "Loss: \n",
      " 0.00016221791083373304\n",
      "\n",
      "\n",
      "Epoch: 879\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90326613]\n",
      " [0.87391177]\n",
      " [0.88639101]]\n",
      "Loss: \n",
      " 0.00016219489118619038\n",
      "\n",
      "\n",
      "Epoch: 880\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.903272  ]\n",
      " [0.87391807]\n",
      " [0.88639755]]\n",
      "Loss: \n",
      " 0.00016217203165766518\n",
      "\n",
      "\n",
      "Epoch: 881\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90327786]\n",
      " [0.87392434]\n",
      " [0.88640407]]\n",
      "Loss: \n",
      " 0.00016214933088688597\n",
      "\n",
      "\n",
      "Epoch: 882\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90328368]\n",
      " [0.87393058]\n",
      " [0.88641056]]\n",
      "Loss: \n",
      " 0.00016212678752443646\n",
      "\n",
      "\n",
      "Epoch: 883\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90328949]\n",
      " [0.87393679]\n",
      " [0.88641702]]\n",
      "Loss: \n",
      " 0.00016210440023265026\n",
      "\n",
      "\n",
      "Epoch: 884\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90329527]\n",
      " [0.87394298]\n",
      " [0.88642345]]\n",
      "Loss: \n",
      " 0.00016208216768550084\n",
      "\n",
      "\n",
      "Epoch: 885\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90330102]\n",
      " [0.87394914]\n",
      " [0.88642986]]\n",
      "Loss: \n",
      " 0.00016206008856850288\n",
      "\n",
      "\n",
      "Epoch: 886\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90330675]\n",
      " [0.87395527]\n",
      " [0.88643624]]\n",
      "Loss: \n",
      " 0.00016203816157859982\n",
      "\n",
      "\n",
      "Epoch: 887\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90331246]\n",
      " [0.87396138]\n",
      " [0.88644259]]\n",
      "Loss: \n",
      " 0.00016201638542406554\n",
      "\n",
      "\n",
      "Epoch: 888\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90331815]\n",
      " [0.87396746]\n",
      " [0.88644892]]\n",
      "Loss: \n",
      " 0.00016199475882440538\n",
      "\n",
      "\n",
      "Epoch: 889\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90332381]\n",
      " [0.87397351]\n",
      " [0.88645522]]\n",
      "Loss: \n",
      " 0.00016197328051025325\n",
      "\n",
      "\n",
      "Epoch: 890\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90332944]\n",
      " [0.87397954]\n",
      " [0.8864615 ]]\n",
      "Loss: \n",
      " 0.00016195194922327149\n",
      "\n",
      "\n",
      "Epoch: 891\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90333506]\n",
      " [0.87398554]\n",
      " [0.88646775]]\n",
      "Loss: \n",
      " 0.00016193076371605154\n",
      "\n",
      "\n",
      "Epoch: 892\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90334065]\n",
      " [0.87399151]\n",
      " [0.88647397]]\n",
      "Loss: \n",
      " 0.00016190972275201127\n",
      "\n",
      "\n",
      "Epoch: 893\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90334622]\n",
      " [0.87399746]\n",
      " [0.88648017]]\n",
      "Loss: \n",
      " 0.000161888825105314\n",
      "\n",
      "\n",
      "Epoch: 894\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90335176]\n",
      " [0.87400338]\n",
      " [0.88648634]]\n",
      "Loss: \n",
      " 0.00016186806956075228\n",
      "\n",
      "\n",
      "Epoch: 895\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90335728]\n",
      " [0.87400927]\n",
      " [0.88649249]]\n",
      "Loss: \n",
      " 0.00016184745491366743\n",
      "\n",
      "\n",
      "Epoch: 896\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90336278]\n",
      " [0.87401514]\n",
      " [0.88649861]]\n",
      "Loss: \n",
      " 0.0001618269799698437\n",
      "\n",
      "\n",
      "Epoch: 897\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90336826]\n",
      " [0.87402098]\n",
      " [0.8865047 ]]\n",
      "Loss: \n",
      " 0.00016180664354542744\n",
      "\n",
      "\n",
      "Epoch: 898\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90337371]\n",
      " [0.8740268 ]\n",
      " [0.88651077]]\n",
      "Loss: \n",
      " 0.00016178644446682115\n",
      "\n",
      "\n",
      "Epoch: 899\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90337914]\n",
      " [0.87403259]\n",
      " [0.88651681]]\n",
      "Loss: \n",
      " 0.00016176638157060485\n",
      "\n",
      "\n",
      "Epoch: 900\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90338455]\n",
      " [0.87403835]\n",
      " [0.88652283]]\n",
      "Loss: \n",
      " 0.0001617464537034336\n",
      "\n",
      "\n",
      "Epoch: 901\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90338993]\n",
      " [0.8740441 ]\n",
      " [0.88652883]]\n",
      "Loss: \n",
      " 0.00016172665972195372\n",
      "\n",
      "\n",
      "Epoch: 902\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9033953 ]\n",
      " [0.87404981]\n",
      " [0.8865348 ]]\n",
      "Loss: \n",
      " 0.0001617069984927165\n",
      "\n",
      "\n",
      "Epoch: 903\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90340064]\n",
      " [0.8740555 ]\n",
      " [0.88654074]]\n",
      "Loss: \n",
      " 0.00016168746889207945\n",
      "\n",
      "\n",
      "Epoch: 904\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90340596]\n",
      " [0.87406117]\n",
      " [0.88654666]]\n",
      "Loss: \n",
      " 0.00016166806980612847\n",
      "\n",
      "\n",
      "Epoch: 905\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90341125]\n",
      " [0.87406681]\n",
      " [0.88655256]]\n",
      "Loss: \n",
      " 0.0001616488001305868\n",
      "\n",
      "\n",
      "Epoch: 906\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90341653]\n",
      " [0.87407242]\n",
      " [0.88655843]]\n",
      "Loss: \n",
      " 0.00016162965877073143\n",
      "\n",
      "\n",
      "Epoch: 907\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90342178]\n",
      " [0.87407801]\n",
      " [0.88656428]]\n",
      "Loss: \n",
      " 0.00016161064464130333\n",
      "\n",
      "\n",
      "Epoch: 908\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90342701]\n",
      " [0.87408358]\n",
      " [0.8865701 ]]\n",
      "Loss: \n",
      " 0.00016159175666643287\n",
      "\n",
      "\n",
      "Epoch: 909\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90343222]\n",
      " [0.87408912]\n",
      " [0.8865759 ]]\n",
      "Loss: \n",
      " 0.0001615729937795401\n",
      "\n",
      "\n",
      "Epoch: 910\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90343741]\n",
      " [0.87409464]\n",
      " [0.88658167]]\n",
      "Loss: \n",
      " 0.00016155435492327076\n",
      "\n",
      "\n",
      "Epoch: 911\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90344258]\n",
      " [0.87410013]\n",
      " [0.88658742]]\n",
      "Loss: \n",
      " 0.00016153583904939792\n",
      "\n",
      "\n",
      "Epoch: 912\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90344772]\n",
      " [0.8741056 ]\n",
      " [0.88659315]]\n",
      "Loss: \n",
      " 0.00016151744511875275\n",
      "\n",
      "\n",
      "Epoch: 913\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90345285]\n",
      " [0.87411104]\n",
      " [0.88659885]]\n",
      "Loss: \n",
      " 0.00016149917210113774\n",
      "\n",
      "\n",
      "Epoch: 914\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90345795]\n",
      " [0.87411646]\n",
      " [0.88660453]]\n",
      "Loss: \n",
      " 0.00016148101897524588\n",
      "\n",
      "\n",
      "Epoch: 915\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90346303]\n",
      " [0.87412186]\n",
      " [0.88661019]]\n",
      "Loss: \n",
      " 0.0001614629847285912\n",
      "\n",
      "\n",
      "Epoch: 916\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90346809]\n",
      " [0.87412723]\n",
      " [0.88661582]]\n",
      "Loss: \n",
      " 0.00016144506835741098\n",
      "\n",
      "\n",
      "Epoch: 917\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90347314]\n",
      " [0.87413258]\n",
      " [0.88662143]]\n",
      "Loss: \n",
      " 0.00016142726886661212\n",
      "\n",
      "\n",
      "Epoch: 918\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90347816]\n",
      " [0.87413791]\n",
      " [0.88662702]]\n",
      "Loss: \n",
      " 0.00016140958526968132\n",
      "\n",
      "\n",
      "Epoch: 919\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90348315]\n",
      " [0.87414321]\n",
      " [0.88663258]]\n",
      "Loss: \n",
      " 0.00016139201658860297\n",
      "\n",
      "\n",
      "Epoch: 920\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90348813]\n",
      " [0.87414849]\n",
      " [0.88663812]]\n",
      "Loss: \n",
      " 0.0001613745618537954\n",
      "\n",
      "\n",
      "Epoch: 921\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90349309]\n",
      " [0.87415374]\n",
      " [0.88664364]]\n",
      "Loss: \n",
      " 0.00016135722010403696\n",
      "\n",
      "\n",
      "Epoch: 922\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90349803]\n",
      " [0.87415897]\n",
      " [0.88664913]]\n",
      "Loss: \n",
      " 0.00016133999038637857\n",
      "\n",
      "\n",
      "Epoch: 923\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90350295]\n",
      " [0.87416418]\n",
      " [0.8866546 ]]\n",
      "Loss: \n",
      " 0.000161322871756082\n",
      "\n",
      "\n",
      "Epoch: 924\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90350784]\n",
      " [0.87416937]\n",
      " [0.88666005]]\n",
      "Loss: \n",
      " 0.00016130586327654705\n",
      "\n",
      "\n",
      "Epoch: 925\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90351272]\n",
      " [0.87417453]\n",
      " [0.88666548]]\n",
      "Loss: \n",
      " 0.00016128896401922812\n",
      "\n",
      "\n",
      "Epoch: 926\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90351758]\n",
      " [0.87417968]\n",
      " [0.88667088]]\n",
      "Loss: \n",
      " 0.00016127217306358227\n",
      "\n",
      "\n",
      "Epoch: 927\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90352241]\n",
      " [0.87418479]\n",
      " [0.88667626]]\n",
      "Loss: \n",
      " 0.00016125548949697799\n",
      "\n",
      "\n",
      "Epoch: 928\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90352723]\n",
      " [0.87418989]\n",
      " [0.88668162]]\n",
      "Loss: \n",
      " 0.0001612389124146329\n",
      "\n",
      "\n",
      "Epoch: 929\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90353203]\n",
      " [0.87419496]\n",
      " [0.88668696]]\n",
      "Loss: \n",
      " 0.00016122244091956142\n",
      "\n",
      "\n",
      "Epoch: 930\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9035368 ]\n",
      " [0.87420001]\n",
      " [0.88669228]]\n",
      "Loss: \n",
      " 0.00016120607412246823\n",
      "\n",
      "\n",
      "Epoch: 931\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90354156]\n",
      " [0.87420504]\n",
      " [0.88669757]]\n",
      "Loss: \n",
      " 0.00016118981114172034\n",
      "\n",
      "\n",
      "Epoch: 932\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9035463 ]\n",
      " [0.87421005]\n",
      " [0.88670284]]\n",
      "Loss: \n",
      " 0.00016117365110325123\n",
      "\n",
      "\n",
      "Epoch: 933\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90355102]\n",
      " [0.87421503]\n",
      " [0.88670809]]\n",
      "Loss: \n",
      " 0.0001611575931405091\n",
      "\n",
      "\n",
      "Epoch: 934\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90355572]\n",
      " [0.87422   ]\n",
      " [0.88671332]]\n",
      "Loss: \n",
      " 0.0001611416363943815\n",
      "\n",
      "\n",
      "Epoch: 935\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9035604 ]\n",
      " [0.87422494]\n",
      " [0.88671853]]\n",
      "Loss: \n",
      " 0.0001611257800131405\n",
      "\n",
      "\n",
      "Epoch: 936\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90356506]\n",
      " [0.87422985]\n",
      " [0.88672372]]\n",
      "Loss: \n",
      " 0.00016111002315236252\n",
      "\n",
      "\n",
      "Epoch: 937\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9035697 ]\n",
      " [0.87423475]\n",
      " [0.88672888]]\n",
      "Loss: \n",
      " 0.00016109436497488067\n",
      "\n",
      "\n",
      "Epoch: 938\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90357432]\n",
      " [0.87423963]\n",
      " [0.88673402]]\n",
      "Loss: \n",
      " 0.00016107880465070833\n",
      "\n",
      "\n",
      "Epoch: 939\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90357893]\n",
      " [0.87424448]\n",
      " [0.88673915]]\n",
      "Loss: \n",
      " 0.0001610633413569763\n",
      "\n",
      "\n",
      "Epoch: 940\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90358351]\n",
      " [0.87424931]\n",
      " [0.88674425]]\n",
      "Loss: \n",
      " 0.00016104797427788162\n",
      "\n",
      "\n",
      "Epoch: 941\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90358808]\n",
      " [0.87425413]\n",
      " [0.88674933]]\n",
      "Loss: \n",
      " 0.00016103270260461465\n",
      "\n",
      "\n",
      "Epoch: 942\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90359263]\n",
      " [0.87425892]\n",
      " [0.88675439]]\n",
      "Loss: \n",
      " 0.00016101752553529346\n",
      "\n",
      "\n",
      "Epoch: 943\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90359716]\n",
      " [0.87426368]\n",
      " [0.88675942]]\n",
      "Loss: \n",
      " 0.0001610024422749188\n",
      "\n",
      "\n",
      "Epoch: 944\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90360167]\n",
      " [0.87426843]\n",
      " [0.88676444]]\n",
      "Loss: \n",
      " 0.0001609874520353035\n",
      "\n",
      "\n",
      "Epoch: 945\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90360616]\n",
      " [0.87427316]\n",
      " [0.88676944]]\n",
      "Loss: \n",
      " 0.00016097255403500887\n",
      "\n",
      "\n",
      "Epoch: 946\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90361063]\n",
      " [0.87427787]\n",
      " [0.88677441]]\n",
      "Loss: \n",
      " 0.00016095774749929164\n",
      "\n",
      "\n",
      "Epoch: 947\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90361509]\n",
      " [0.87428255]\n",
      " [0.88677937]]\n",
      "Loss: \n",
      " 0.00016094303166004444\n",
      "\n",
      "\n",
      "Epoch: 948\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90361952]\n",
      " [0.87428722]\n",
      " [0.88678431]]\n",
      "Loss: \n",
      " 0.0001609284057557383\n",
      "\n",
      "\n",
      "Epoch: 949\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90362394]\n",
      " [0.87429186]\n",
      " [0.88678922]]\n",
      "Loss: \n",
      " 0.00016091386903136165\n",
      "\n",
      "\n",
      "Epoch: 950\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90362834]\n",
      " [0.87429648]\n",
      " [0.88679412]]\n",
      "Loss: \n",
      " 0.0001608994207383623\n",
      "\n",
      "\n",
      "Epoch: 951\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90363273]\n",
      " [0.87430109]\n",
      " [0.88679899]]\n",
      "Loss: \n",
      " 0.00016088506013459515\n",
      "\n",
      "\n",
      "Epoch: 952\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90363709]\n",
      " [0.87430567]\n",
      " [0.88680385]]\n",
      "Loss: \n",
      " 0.00016087078648426546\n",
      "\n",
      "\n",
      "Epoch: 953\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90364144]\n",
      " [0.87431023]\n",
      " [0.88680868]]\n",
      "Loss: \n",
      " 0.00016085659905786933\n",
      "\n",
      "\n",
      "Epoch: 954\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90364577]\n",
      " [0.87431478]\n",
      " [0.8868135 ]]\n",
      "Loss: \n",
      " 0.0001608424971321416\n",
      "\n",
      "\n",
      "Epoch: 955\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90365008]\n",
      " [0.8743193 ]\n",
      " [0.88681829]]\n",
      "Loss: \n",
      " 0.00016082847998999462\n",
      "\n",
      "\n",
      "Epoch: 956\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90365437]\n",
      " [0.8743238 ]\n",
      " [0.88682307]]\n",
      "Loss: \n",
      " 0.00016081454692048447\n",
      "\n",
      "\n",
      "Epoch: 957\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90365865]\n",
      " [0.87432828]\n",
      " [0.88682783]]\n",
      "Loss: \n",
      " 0.00016080069721872392\n",
      "\n",
      "\n",
      "Epoch: 958\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90366291]\n",
      " [0.87433275]\n",
      " [0.88683256]]\n",
      "Loss: \n",
      " 0.0001607869301858619\n",
      "\n",
      "\n",
      "Epoch: 959\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90366715]\n",
      " [0.87433719]\n",
      " [0.88683728]]\n",
      "Loss: \n",
      " 0.00016077324512901028\n",
      "\n",
      "\n",
      "Epoch: 960\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90367138]\n",
      " [0.87434161]\n",
      " [0.88684198]]\n",
      "Loss: \n",
      " 0.0001607596413611984\n",
      "\n",
      "\n",
      "Epoch: 961\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90367558]\n",
      " [0.87434602]\n",
      " [0.88684666]]\n",
      "Loss: \n",
      " 0.00016074611820132231\n",
      "\n",
      "\n",
      "Epoch: 962\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90367977]\n",
      " [0.8743504 ]\n",
      " [0.88685132]]\n",
      "Loss: \n",
      " 0.00016073267497409478\n",
      "\n",
      "\n",
      "Epoch: 963\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90368395]\n",
      " [0.87435477]\n",
      " [0.88685596]]\n",
      "Loss: \n",
      " 0.00016071931100998226\n",
      "\n",
      "\n",
      "Epoch: 964\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9036881 ]\n",
      " [0.87435911]\n",
      " [0.88686058]]\n",
      "Loss: \n",
      " 0.00016070602564517453\n",
      "\n",
      "\n",
      "Epoch: 965\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90369224]\n",
      " [0.87436344]\n",
      " [0.88686519]]\n",
      "Loss: \n",
      " 0.00016069281822151773\n",
      "\n",
      "\n",
      "Epoch: 966\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90369636]\n",
      " [0.87436775]\n",
      " [0.88686977]]\n",
      "Loss: \n",
      " 0.00016067968808647817\n",
      "\n",
      "\n",
      "Epoch: 967\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90370047]\n",
      " [0.87437204]\n",
      " [0.88687434]]\n",
      "Loss: \n",
      " 0.00016066663459307276\n",
      "\n",
      "\n",
      "Epoch: 968\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90370456]\n",
      " [0.87437631]\n",
      " [0.88687888]]\n",
      "Loss: \n",
      " 0.00016065365709985103\n",
      "\n",
      "\n",
      "Epoch: 969\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90370863]\n",
      " [0.87438056]\n",
      " [0.88688341]]\n",
      "Loss: \n",
      " 0.00016064075497081759\n",
      "\n",
      "\n",
      "Epoch: 970\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90371269]\n",
      " [0.87438479]\n",
      " [0.88688792]]\n",
      "Loss: \n",
      " 0.00016062792757540577\n",
      "\n",
      "\n",
      "Epoch: 971\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90371673]\n",
      " [0.874389  ]\n",
      " [0.88689241]]\n",
      "Loss: \n",
      " 0.00016061517428841266\n",
      "\n",
      "\n",
      "Epoch: 972\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90372075]\n",
      " [0.8743932 ]\n",
      " [0.88689689]]\n",
      "Loss: \n",
      " 0.00016060249448996797\n",
      "\n",
      "\n",
      "Epoch: 973\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90372475]\n",
      " [0.87439737]\n",
      " [0.88690134]]\n",
      "Loss: \n",
      " 0.00016058988756547626\n",
      "\n",
      "\n",
      "Epoch: 974\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90372874]\n",
      " [0.87440153]\n",
      " [0.88690578]]\n",
      "Loss: \n",
      " 0.00016057735290557834\n",
      "\n",
      "\n",
      "Epoch: 975\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90373272]\n",
      " [0.87440567]\n",
      " [0.8869102 ]]\n",
      "Loss: \n",
      " 0.00016056488990610137\n",
      "\n",
      "\n",
      "Epoch: 976\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90373668]\n",
      " [0.87440979]\n",
      " [0.8869146 ]]\n",
      "Loss: \n",
      " 0.0001605524979680132\n",
      "\n",
      "\n",
      "Epoch: 977\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90374062]\n",
      " [0.87441389]\n",
      " [0.88691898]]\n",
      "Loss: \n",
      " 0.0001605401764973873\n",
      "\n",
      "\n",
      "Epoch: 978\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90374454]\n",
      " [0.87441798]\n",
      " [0.88692334]]\n",
      "Loss: \n",
      " 0.00016052792490533788\n",
      "\n",
      "\n",
      "Epoch: 979\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90374845]\n",
      " [0.87442205]\n",
      " [0.88692769]]\n",
      "Loss: \n",
      " 0.000160515742607994\n",
      "\n",
      "\n",
      "Epoch: 980\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90375235]\n",
      " [0.87442609]\n",
      " [0.88693202]]\n",
      "Loss: \n",
      " 0.00016050362902645762\n",
      "\n",
      "\n",
      "Epoch: 981\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90375623]\n",
      " [0.87443012]\n",
      " [0.88693633]]\n",
      "Loss: \n",
      " 0.000160491583586742\n",
      "\n",
      "\n",
      "Epoch: 982\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90376009]\n",
      " [0.87443414]\n",
      " [0.88694063]]\n",
      "Loss: \n",
      " 0.00016047960571974587\n",
      "\n",
      "\n",
      "Epoch: 983\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90376393]\n",
      " [0.87443813]\n",
      " [0.8869449 ]]\n",
      "Loss: \n",
      " 0.00016046769486120345\n",
      "\n",
      "\n",
      "Epoch: 984\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90376777]\n",
      " [0.87444211]\n",
      " [0.88694916]]\n",
      "Loss: \n",
      " 0.00016045585045164413\n",
      "\n",
      "\n",
      "Epoch: 985\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90377158]\n",
      " [0.87444607]\n",
      " [0.8869534 ]]\n",
      "Loss: \n",
      " 0.00016044407193635527\n",
      "\n",
      "\n",
      "Epoch: 986\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90377538]\n",
      " [0.87445001]\n",
      " [0.88695763]]\n",
      "Loss: \n",
      " 0.00016043235876532706\n",
      "\n",
      "\n",
      "Epoch: 987\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90377917]\n",
      " [0.87445394]\n",
      " [0.88696184]]\n",
      "Loss: \n",
      " 0.0001604207103932295\n",
      "\n",
      "\n",
      "Epoch: 988\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90378294]\n",
      " [0.87445784]\n",
      " [0.88696603]]\n",
      "Loss: \n",
      " 0.00016040912627936205\n",
      "\n",
      "\n",
      "Epoch: 989\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90378669]\n",
      " [0.87446173]\n",
      " [0.8869702 ]]\n",
      "Loss: \n",
      " 0.0001603976058876091\n",
      "\n",
      "\n",
      "Epoch: 990\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90379043]\n",
      " [0.87446561]\n",
      " [0.88697436]]\n",
      "Loss: \n",
      " 0.0001603861486864131\n",
      "\n",
      "\n",
      "Epoch: 991\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90379415]\n",
      " [0.87446946]\n",
      " [0.8869785 ]]\n",
      "Loss: \n",
      " 0.0001603747541487218\n",
      "\n",
      "\n",
      "Epoch: 992\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90379786]\n",
      " [0.8744733 ]\n",
      " [0.88698262]]\n",
      "Loss: \n",
      " 0.0001603634217519581\n",
      "\n",
      "\n",
      "Epoch: 993\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90380156]\n",
      " [0.87447712]\n",
      " [0.88698672]]\n",
      "Loss: \n",
      " 0.0001603521509779788\n",
      "\n",
      "\n",
      "Epoch: 994\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90380523]\n",
      " [0.87448092]\n",
      " [0.88699081]]\n",
      "Loss: \n",
      " 0.00016034094131303322\n",
      "\n",
      "\n",
      "Epoch: 995\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9038089 ]\n",
      " [0.87448471]\n",
      " [0.88699489]]\n",
      "Loss: \n",
      " 0.00016032979224772683\n",
      "\n",
      "\n",
      "Epoch: 996\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90381255]\n",
      " [0.87448848]\n",
      " [0.88699894]]\n",
      "Loss: \n",
      " 0.00016031870327698822\n",
      "\n",
      "\n",
      "Epoch: 997\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90381618]\n",
      " [0.87449224]\n",
      " [0.88700298]]\n",
      "Loss: \n",
      " 0.00016030767390002652\n",
      "\n",
      "\n",
      "Epoch: 998\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9038198 ]\n",
      " [0.87449597]\n",
      " [0.88700701]]\n",
      "Loss: \n",
      " 0.00016029670362028997\n",
      "\n",
      "\n",
      "Epoch: 999\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90382341]\n",
      " [0.8744997 ]\n",
      " [0.88701101]]\n",
      "Loss: \n",
      " 0.00016028579194543967\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "print(np.amax(X, axis=0))\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) \n",
    "        return o \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2)\n",
    "        self.W1 += l_rate*X.T.dot(self.z2_delta)\n",
    "        self.W2 += l_rate*self.z2.T.dot(self.o_delta)\n",
    "\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "NN = Neural_Network()\n",
    "l_rate = 0.1 \n",
    "for i in range(1000):\n",
    "    print(\"Epoch:\",i)\n",
    "    print(\"l_rate\",l_rate)\n",
    "    print (\"Input: \\n\",str(X))\n",
    "    print (\"Actual Output: \\n\",str(y))\n",
    "    print (\"Predicted Output: \\n\",str(NN.forward(X)) )\n",
    "    print (\"Loss: \\n\",str(np.mean(np.square(y - NN.forward(X)))))\n",
    "    print(\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41393d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 values of data is:\n",
      "     Outlook Temperature Humidity  Windy PlayTennis\n",
      "0     Sunny         Hot     High  False         No\n",
      "1     Sunny         Hot     High   True         No\n",
      "2  Overcast         Hot     High  False        Yes\n",
      "3     Rainy        Mild     High  False        Yes\n",
      "4     Rainy        Cool   Normal  False        Yes\n",
      "\n",
      "The First 5 values of train data is\n",
      "     Outlook Temperature Humidity  Windy\n",
      "0     Sunny         Hot     High  False\n",
      "1     Sunny         Hot     High   True\n",
      "2  Overcast         Hot     High  False\n",
      "3     Rainy        Mild     High  False\n",
      "4     Rainy        Cool   Normal  False\n",
      "\n",
      "The First 5 values of train output is\n",
      " 0     No\n",
      "1     No\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: PlayTennis, dtype: object\n",
      "\n",
      "Now the train data is:\n",
      "    Outlook  Temperature  Humidity  Windy\n",
      "0        2            1         0      0\n",
      "1        2            1         0      1\n",
      "2        0            1         0      0\n",
      "3        1            2         0      0\n",
      "4        1            0         1      0\n",
      "\n",
      "Now the train output is\n",
      " [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Accuracy is: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv('pro6.csv') \n",
    "print(\"The first 5 values of data is:\\n\",data.head())\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "print(\"\\nThe First 5 values of train data is\\n\",X.head())\n",
    "y = data.iloc[:,-1]\n",
    "print(\"\\nThe First 5 values of train output is\\n\",y.head())\n",
    "\n",
    "le_outlook = LabelEncoder()\n",
    "X.Outlook = le_outlook.fit_transform(X.Outlook) \n",
    "le_Temperature = LabelEncoder() \n",
    "X.Temperature = le_Temperature.fit_transform(X.Temperature)\n",
    "le_Humidity = LabelEncoder()\n",
    "X.Humidity = le_Humidity.fit_transform(X.Humidity)\n",
    "le_Windy = LabelEncoder()\n",
    "X.Windy = le_Windy.fit_transform(X.Windy)\n",
    "\n",
    "print(\"\\nNow the train data is:\\n\", X.head())\n",
    "le_PlayTennis = LabelEncoder()\n",
    "y = le_PlayTennis.fit_transform(y)\n",
    "print(\"\\nNow the train output is\\n\",y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is:\",accuracy_score(classifier.predict(X_test),y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1da7269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandakumar V\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Nandakumar V\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nandakumar V\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !! \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'])\n",
    "print(type(X))\n",
    "y = pd.DataFrame(iris.target, columns=[\"Targets\"])\n",
    "\n",
    "\n",
    "# Build K Means Model\n",
    "kmeans_model = KMeans(n_clusters=3)\n",
    "kmeans_model.fit(X)\n",
    "\n",
    "# Visualize the clustering results for K-Means\n",
    "plt.figure(figsize=(14, 7))\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y.Targets], s=40, label=\"Real Clusters\")\n",
    "plt.title(\"Real Clusters\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot K-Means classifications\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[kmeans_model.labels_], s=40, label=\"K-Means Clustering\")\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.legend()\n",
    "\n",
    "# Transform data for GMM\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "xsa = scaler.transform(X)\n",
    "xs = pd.DataFrame(xsa, columns=X.columns)\n",
    "\n",
    "# Build GMM Model\n",
    "gmm = GaussianMixture(n_components=3)\n",
    "gmm.fit(xs)\n",
    "\n",
    "# Visualize the clustering results for GMM\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[gmm.predict(xs)], s=40, label=\"GMM Clustering\")\n",
    "plt.title(\"GMM Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Done !! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b63ff020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data set Loaded...\n",
      "Label 0 - setosa\n",
      "Label 1 - versicolor\n",
      "Label 2 - virginica\n",
      "Results of Classification using k-nn with k=1\n",
      "Sample [5.2 3.4 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.7 2.6 6.9 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.2 1.2 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.9 3.1 1.5 0.1] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.4 1.5 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.9 3.  5.1 1.8] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.7 3.  6.1 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.6 3.2 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.8 4.  1.2 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.5 3.  5.8 2.2] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.4 2.9 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.6 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.7 3.8 6.7 2.2] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.7 2.5 5.  2. ] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.2 3.4 5.4 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris Data set Loaded...\")\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.1)\n",
    "\n",
    "#random_state=0\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "    print(\"Label\", i, \"-\",str(iris.target_names[i]))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(\"Results of Classification using k-nn with k=1\")\n",
    "\n",
    "for r in range(0,len(X_test)):\n",
    "    print(\"Sample\", str(X_test[r]), \"Actual-label:\", str(y_test[r]), \"Predicted-label:\", str(y_pred[r]))\n",
    "\n",
    "    print(\"Classification Accuracy :\", classifier.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4b5e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def local_regression(x0, X,Y,tau):\n",
    "    x0=[1,x0]\n",
    "    X=[[1,i] for i in X ]\n",
    "    X=np.asarray(X)\n",
    "    xw = (X.T) * np.exp(np.sum((X-x0)**2,axis=1)/(-2*tau)) \n",
    "    beta = np.linalg.pinv(xw @ X) @ xw @ Y @x0\n",
    "    return beta\n",
    "\n",
    "def draw(tau):\n",
    "    prediction=[local_regression(x0,X,Y,tau) for x0 in domain]\n",
    "    plt.plot(X,Y,'o',color=\"black\")\n",
    "    plt.plot(domain,prediction,color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X = np.linspace(-3,3,num=1000)\n",
    "domain = X\n",
    "Y = np.log(np.abs(X**2-1)+.5)\n",
    "\n",
    "draw(10)\n",
    "draw(0.1)\n",
    "draw(0.01)\n",
    "draw(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0b964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
